"""
Naver Smart Place Center Automation using Selenium (Python 3.13 compatible!)
âš ï¸ ì£¼ì˜: ë„¤ì´ë²„ëŠ” ê³µì‹ ë¦¬ë·° ê´€ë¦¬ APIë¥¼ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
ì´ ëª¨ë“ˆì€ ê°œì¸ ì‚¬ìš© ëª©ì ìœ¼ë¡œë§Œ ì‚¬ìš©í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.
"""

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
import json
import os
import time
import logging
import hashlib
import re
from typing import List, Dict, Optional
from datetime import datetime, timedelta
from config import settings
from fastapi import HTTPException

logger = logging.getLogger(__name__)


class NaverPlaceAutomationSelenium:
    """Naver Smart Place Center automation using Selenium"""
    
    def __init__(self):
        self.session_file = os.path.join(settings.data_dir, "naver_sessions", "session_selenium.json")
        os.makedirs(os.path.dirname(self.session_file), exist_ok=True)
        
        # ğŸš€ Multi-account support
        self.active_user_id = "default"  # Default user
        
        # ğŸ”’ Thread Lock for race condition prevention
        import threading
        self._user_lock = threading.Lock()  # API í˜¸ì¶œ ê°„ user_id ë³´í˜¸
        
        # ğŸš€ Performance optimization: Cache for places list (userë³„ë¡œ ë¶„ë¦¬!)
        self._places_cache: Dict[str, List[Dict]] = {}  # {user_id: [places]}
        self._places_cache_time: Dict[str, datetime] = {}  # {user_id: datetime}
        self._cache_ttl = timedelta(minutes=5)  # 5ë¶„ê°„ ìºì‹œ ìœ ì§€

        # ğŸš€ REVIEWS CACHE (Performance & Pagination Fix)
        # Structure: { f"{place_id}:{filter_type}": { 'data': [...], 'time': datetime, 'total': int } }
        self._reviews_cache: Dict[str, Dict] = {}
        self._reviews_cache_ttl = timedelta(minutes=10)  # 10 minutes cache
        
        # ğŸš€ PROGRESS TRACKING (Real-time feedback)
        # Structure: { place_id: { 'status': str, 'count': int, 'message': str, 'timestamp': datetime } }
        self._loading_progress: Dict[str, Dict] = {}
    
    def _load_session_from_mongodb(self, user_id="default"):
        """Load session from MongoDB (cloud storage)
        
        Returns:
            dict with 'cookies', 'user_agent', 'window_size' or None
        """
        try:
            if not settings.use_mongodb or not settings.mongodb_url:
                return None
            
            from utils.db import get_db
            db = get_db()
            if db is None:
                return None
            
            session = db.naver_sessions.find_one({"_id": user_id})
            if session and session.get('cookies'):
                print(f"ğŸ“¦ Found session in MongoDB for user '{user_id}' ({len(session['cookies'])} cookies)")
                
                # ğŸ”§ CRITICAL: User-Agentì™€ window_sizeë„ í•¨ê»˜ ë°˜í™˜
                user_agent = session.get('user_agent')
                window_size = session.get('window_size')
                
                if user_agent:
                    print(f"   âœ… User-Agent: {user_agent[:80]}...")
                if window_size:
                    print(f"   âœ… Window Size: {window_size}")
                
                # Update last_used timestamp
                db.naver_sessions.update_one(
                    {"_id": user_id},
                    {"$set": {"last_used": datetime.utcnow()}}
                )
                
                return {
                    'cookies': session['cookies'],
                    'user_agent': user_agent,
                    'window_size': window_size
                }
            
            return None
        except Exception as e:
            logger.error(f"âŒ MongoDB session load error: {e}")
            return None
    
    def set_active_user(self, user_id="default"):
        """Set the active user ID for this session"""
        self.active_user_id = user_id
        print(f"ğŸ”„ Active user switched to: {user_id}")
    
    def _create_driver(self, headless=True, user_id=None):
        """
        Create and configure Chrome WebDriver
        
        Args:
            headless: Run in headless mode
            user_id: User ID for session loading (if None, uses self.active_user_id)
        """
        # ğŸ”’ user_id íŒŒë¼ë¯¸í„° ìš°ì„  ì‚¬ìš© (race condition ë°©ì§€)
        effective_user_id = user_id if user_id else self.active_user_id
        
        print(f"ğŸŒ Creating Chrome WebDriver for user: {effective_user_id}")
        logger.info(f"ğŸŒ Creating Chrome WebDriver for user: {effective_user_id}")
        
        chrome_options = Options()
        if headless:
            chrome_options.add_argument('--headless=new')
        
        # Essential options for Heroku
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--disable-software-rasterizer')
        chrome_options.add_argument('--disable-extensions')
        chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        
        # Heroku specific - Memory optimization
        chrome_options.add_argument('--single-process')
        chrome_options.add_argument('--disable-setuid-sandbox')
        chrome_options.add_argument('--remote-debugging-port=9222')
        
        # Additional memory saving options for Heroku
        chrome_options.add_argument('--disable-background-networking')
        chrome_options.add_argument('--disable-background-timer-throttling')
        chrome_options.add_argument('--disable-backgrounding-occluded-windows')
        chrome_options.add_argument('--disable-breakpad')
        chrome_options.add_argument('--disable-component-extensions-with-background-pages')
        chrome_options.add_argument('--disable-features=TranslateUI,BlinkGenPropertyTrees')
        chrome_options.add_argument('--disable-ipc-flooding-protection')
        chrome_options.add_argument('--disable-renderer-backgrounding')
        chrome_options.add_argument('--enable-features=NetworkService,NetworkServiceInProcess')
        chrome_options.add_argument('--force-color-profile=srgb')
        chrome_options.add_argument('--hide-scrollbars')
        chrome_options.add_argument('--metrics-recording-only')
        chrome_options.add_argument('--mute-audio')
        
        # Set memory limits
        chrome_options.add_argument('--max_old_space_size=256')
        chrome_options.add_argument('--js-flags=--max-old-space-size=256')
        
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        
        # ğŸ”§ CRITICAL: ê¸°ë³¸ê°’ ì„¤ì • (MongoDBì—ì„œ ë¡œë“œí•œ ê°’ìœ¼ë¡œ ë‚˜ì¤‘ì— ë®ì–´ì“¸ ìˆ˜ ìˆìŒ)
        default_window_size = '1280,720'  # Reduced from 1920x1080
        default_user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        
        chrome_options.add_argument(f'--window-size={default_window_size}')
        chrome_options.add_argument(f'--user-agent={default_user_agent}')
        
        # ğŸ”§ CRITICAL: MongoDBì—ì„œ ì„¸ì…˜ ë©”íƒ€ë°ì´í„° ë¡œë“œ í›„ Chrome ì˜µì…˜ ì—…ë°ì´íŠ¸
        session_data = None
        cookies = None
        
        # Priority 1: Try MongoDB (cloud storage) with effective user ID
        session_data = self._load_session_from_mongodb(effective_user_id)
        if session_data:
            print(f"âœ… Using session from MongoDB (cloud) for user: {effective_user_id}")
            cookies = session_data.get('cookies')
            
            # ğŸ”§ CRITICAL: ì‹¤ì œ ì„¸ì…˜ ìƒì„± ì‹œ ì‚¬ìš©í•œ User-Agentì™€ í•´ìƒë„ ì ìš©
            saved_user_agent = session_data.get('user_agent')
            saved_window_size = session_data.get('window_size')
            
            if saved_user_agent:
                print(f"   ğŸ”§ Applying saved User-Agent: {saved_user_agent[:80]}...")
                # User-Agent ì¬ì„¤ì •
                for i, arg in enumerate(chrome_options.arguments):
                    if arg.startswith('--user-agent='):
                        chrome_options.arguments[i] = f'--user-agent={saved_user_agent}'
                        break
            
            if saved_window_size:
                print(f"   ğŸ”§ Applying saved Window Size: {saved_window_size}")
                # Window Size ì¬ì„¤ì •
                for i, arg in enumerate(chrome_options.arguments):
                    if arg.startswith('--window-size='):
                        chrome_options.arguments[i] = f'--window-size={saved_window_size}'
                        break
        
        # Priority 2: Try local file (fallback)
        elif os.path.exists(self.session_file):
            print("ğŸ“‚ Using session from local file")
            with open(self.session_file, 'r', encoding='utf-8') as f:
                cookies = json.load(f)
        
        # ğŸ”§ CRITICAL: Chrome ì˜µì…˜ ì ìš© í›„ ë“œë¼ì´ë²„ ìƒì„±
        # Check if running on Heroku (has DYNO environment variable)
        if os.environ.get('DYNO'):
            print("ğŸ”§ Detected Heroku environment - using chrome-for-testing paths")
            logger.info("ğŸ”§ Detected Heroku environment")
            
            # chrome-for-testing buildpack installs both Chrome and ChromeDriver in the same directory
            chrome_base = '/app/.chrome-for-testing'
            chrome_bin = f'{chrome_base}/chrome-linux64/chrome'
            chromedriver_path = f'{chrome_base}/chromedriver-linux64/chromedriver'
            
            print(f"   Chrome binary: {chrome_bin}")
            print(f"   ChromeDriver: {chromedriver_path}")
            
            # Verify files exist
            if os.path.exists(chrome_bin):
                print(f"   âœ… Chrome binary found")
            else:
                print(f"   âŒ Chrome binary NOT found at {chrome_bin}")
                # Try to find it
                import glob
                chrome_files = glob.glob('/app/.chrome-for-testing/**/chrome', recursive=True)
                print(f"   Found Chrome at: {chrome_files}")
            
            if os.path.exists(chromedriver_path):
                print(f"   âœ… ChromeDriver found")
            else:
                print(f"   âŒ ChromeDriver NOT found at {chromedriver_path}")
                # Try to find it
                import glob
                driver_files = glob.glob('/app/.chrome-for-testing/**/chromedriver', recursive=True)
                print(f"   Found ChromeDriver at: {driver_files}")
            
            chrome_options.binary_location = chrome_bin
            service = Service(executable_path=chromedriver_path)
        else:
            print("ğŸ’» Local environment - using ChromeDriverManager")
            # Auto-install ChromeDriver for local development
            service = Service(ChromeDriverManager().install())
        
        driver = webdriver.Chrome(service=service, options=chrome_options)
        
        # Load cookies if found
        if cookies:
            logger.info(f"ğŸ“‚ Loading saved session ({len(cookies)} cookies)...")
            print(f"ğŸ“‚ Loading {len(cookies)} cookies...")
            
            # Step 1: Navigate to Naver domain first
            driver.get('https://www.naver.com')
            time.sleep(1)
            
            # Step 2: Load and add all cookies
            cookies_added = 0
            failed_cookies = []
            critical_cookies = ['NID_AUT', 'NID_SES', 'NID_JKL']  # ë„¤ì´ë²„ ì¸ì¦ í•µì‹¬ ì¿ í‚¤
            
            for cookie in cookies:
                try:
                    # Clean up cookie data for Selenium
                    if 'expiry' in cookie:
                        cookie['expiry'] = int(cookie['expiry'])
                    if 'sameSite' in cookie and cookie['sameSite'] not in ['Strict', 'Lax', 'None']:
                        del cookie['sameSite']
                    
                    driver.add_cookie(cookie)
                    cookies_added += 1
                except Exception as e:
                    cookie_name = cookie.get('name', 'unknown')
                    failed_cookies.append(cookie_name)
                    
                    # ğŸ”§ CRITICAL: ì¤‘ìš” ì¿ í‚¤ ì‹¤íŒ¨ ì‹œ ê²½ê³ 
                    if cookie_name in critical_cookies:
                        logger.error(f"âŒ CRITICAL: Failed to add important cookie '{cookie_name}': {e}")
                        print(f"âŒ CRITICAL: Failed to add important cookie '{cookie_name}': {e}")
                    else:
                        logger.debug(f"Failed to add cookie {cookie_name}: {e}")
            
            print(f"âœ… Added {cookies_added}/{len(cookies)} cookies")
            
            # ğŸ”§ ì‹¤íŒ¨í•œ ì¿ í‚¤ ë¡œê¹…
            if failed_cookies:
                print(f"âš ï¸ Failed to add {len(failed_cookies)} cookies: {', '.join(failed_cookies)}")
                logger.warning(f"Failed cookies: {', '.join(failed_cookies)}")
                
                # ì¤‘ìš” ì¿ í‚¤ê°€ ì‹¤íŒ¨í–ˆìœ¼ë©´ ì„¸ì…˜ì´ ì œëŒ€ë¡œ ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ
                critical_failed = [c for c in failed_cookies if c in critical_cookies]
                if critical_failed:
                    print(f"âŒ WARNING: Critical authentication cookies failed: {', '.join(critical_failed)}")
                    print(f"   â†’ Session may not work properly!")
                    logger.error(f"Critical cookies failed: {', '.join(critical_failed)}")
            
            # Step 3: CRITICAL - Refresh page to apply cookies
            print("ğŸ”„ Refreshing page to apply cookies...")
            driver.refresh()
            time.sleep(2)
            
            print("âœ… Session cookies loaded and applied")
        
        logger.info("âœ… WebDriver ready")
        return driver
    
    def _save_session(self, driver):
        """Save browser session"""
        logger.info("ğŸ’¾ Saving session...")
        cookies = driver.get_cookies()
        with open(self.session_file, 'w', encoding='utf-8') as f:
            json.dump(cookies, f, ensure_ascii=False, indent=2)
    
    def login(self, username: str, password: str) -> Dict:
        """Login to Naver"""
        # Check if session already exists and is valid
        if os.path.exists(self.session_file):
            print("ğŸ” Found existing session, checking validity...")
            logger.info("ğŸ” Found existing session, checking validity...")
            
            status = self.check_login_status()
            if status.get('logged_in'):
                print("âœ… Existing session is valid, login not needed!")
                logger.info("âœ… Existing session is valid, login not needed!")
                return {
                    'success': True,
                    'message': 'Already logged in (existing session)'
                }
            else:
                print("âš ï¸ Existing session expired, re-login required")
                logger.info("âš ï¸ Existing session expired, re-login required")
        
        driver = None
        try:
            print(f"ğŸ” Starting Naver login for: {username}")
            logger.info(f"ğŸ” Starting Naver login for: {username}")
            driver = self._create_driver(headless=False)  # Show browser for 2FA
            print("âœ… Driver created successfully")
            
            # Navigate to Naver login
            print("ğŸ“„ Opening Naver login page...")
            logger.info("ğŸ“„ Opening Naver login page...")
            driver.get('https://nid.naver.com/nidlogin.login')
            time.sleep(2)
            
            # Fill login form using JavaScript to avoid bot detection
            print("âŒ¨ï¸ Filling login form...")
            logger.info("âŒ¨ï¸ Filling login form...")
            id_input = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.ID, 'id'))
            )
            pw_input = driver.find_element(By.ID, 'pw')
            
            # Use JavaScript to set values (more human-like)
            driver.execute_script(f"document.getElementById('id').value = '{username}';")
            time.sleep(0.5)
            driver.execute_script(f"document.getElementById('pw').value = '{password}';")
            time.sleep(0.5)
            
            # Click login button
            print("ğŸ–±ï¸ Clicking login button...")
            logger.info("ğŸ–±ï¸ Clicking login button...")
            login_btn = driver.find_element(By.CSS_SELECTOR, '.btn_login')
            login_btn.click()
            
            # Wait for login result (longer wait for 2FA)
            print("â³ Waiting for login result (2ì°¨ ì¸ì¦ì´ í•„ìš”í•˜ë©´ 60ì´ˆ ë‚´ì— ì™„ë£Œí•´ì£¼ì„¸ìš”!)...")
            logger.info("â³ Waiting for login result (2ì°¨ ì¸ì¦ ëŒ€ê¸°)...")
            
            # Wait up to 60 seconds for successful login
            max_wait = 60
            start_time = time.time()
            
            while time.time() - start_time < max_wait:
                current_url = driver.current_url
                
                # ğŸš€ NEW: Handle device registration popup
                if 'deviceConfirm' in current_url:
                    print("ğŸ“± Device registration page detected...")
                    try:
                        # Look for "ë‚˜ì¤‘ì—" or "í™•ì¸" or "ë“±ë¡" button
                        buttons_to_try = [
                            ("//button[contains(., 'ë‚˜ì¤‘ì—')]", "ë‚˜ì¤‘ì—"),
                            ("//button[contains(., 'í™•ì¸')]", "í™•ì¸"),
                            ("//a[contains(., 'ë‚˜ì¤‘ì—')]", "ë‚˜ì¤‘ì— ë§í¬"),
                            (".btn_confirm", "í™•ì¸ ë²„íŠ¼"),
                        ]
                        
                        clicked = False
                        for xpath, name in buttons_to_try:
                            try:
                                if xpath.startswith("//"):
                                    btn = driver.find_element(By.XPATH, xpath)
                                else:
                                    btn = driver.find_element(By.CSS_SELECTOR, xpath)
                                driver.execute_script("arguments[0].click();", btn)
                                print(f"  âœ… Clicked '{name}' on device registration page")
                                clicked = True
                                time.sleep(2)
                                break
                            except:
                                continue
                        
                        if not clicked:
                            print("  âš ï¸ Could not find button on device registration page")
                            print("  ğŸ’¡ Please click manually in the browser window!")
                            time.sleep(5)  # Give user time to click manually
                            
                    except Exception as e:
                        print(f"  âš ï¸ Device registration handling error: {e}")
                    
                    time.sleep(2)
                    continue
                
                # Check if login successful (NOT on login/device pages)
                if 'naver.com' in current_url and 'nidlogin' not in current_url and 'deviceConfirm' not in current_url:
                    print(f"âœ… Login successful! (waited {int(time.time() - start_time)}s)")
                    logger.info("âœ… Login successful!")
                    break
                
                # Check if still on login page or 2FA page
                if 'nidlogin' in current_url or 'deviceConfirm' in current_url:
                    time.sleep(2)
                    continue
                    
                break
            
            time.sleep(2)  # Extra wait
            
            # Check if login was successful
            current_url = driver.current_url
            page_title = driver.title
            print(f"ğŸ”— Current URL: {current_url}")
            print(f"ğŸ“„ Page title: {page_title}")
            logger.info(f"ğŸ”— Current URL: {current_url}")
            logger.info(f"ğŸ“„ Page title: {page_title}")
            
            # ğŸš€ STRICT CHECK: Must NOT be on login/device pages
            if 'naver.com' in current_url and 'nidlogin' not in current_url and 'deviceConfirm' not in current_url:
                # Login successful
                print("âœ… Login successful!")
                logger.info("âœ… Login successful!")
                self._save_session(driver)
                return {
                    'success': True,
                    'message': 'Successfully logged in to Naver'
                }
            else:
                # Check for error message
                print("âŒ Login failed - checking error message...")
                logger.error("âŒ Login failed - checking error message...")
                
                # Try multiple error selectors
                error_msg = None
                for selector in ['.error_message', '.error', '.alert_error', '#err_common']:
                    try:
                        error_elem = driver.find_element(By.CSS_SELECTOR, selector)
                        error_msg = error_elem.text
                        if error_msg:
                            break
                    except:
                        continue
                
                if not error_msg:
                    # Get page source for debugging
                    page_source = driver.page_source[:500]
                    print(f"ğŸ“„ Page source preview: {page_source}")
                    logger.error(f"ğŸ“„ Page source preview: {page_source}")
                    error_msg = "Could not detect error message. Please check credentials or try manual login."
                
                print(f"âŒ Login failed: {error_msg}")
                logger.error(f"âŒ Login failed: {error_msg}")
                return {
                    'success': False,
                    'message': f'Login failed: {error_msg}'
                }
        
        except Exception as e:
            error_msg = str(e)
            print(f"âŒ Login error: {error_msg}")
            logger.error(f"âŒ Login error: {error_msg}")
            import traceback
            error_trace = traceback.format_exc()
            print(f"Full traceback:\n{error_trace}")
            logger.error(f"Full traceback:\n{error_trace}")
            return {
                'success': False,
                'message': f'Login error: {error_msg}'
            }
        
        finally:
            if driver:
                driver.quit()
    
    def check_login_status(self) -> Dict:
        """Check if logged in to Naver (based on session file or MongoDB)"""
        print(f"ğŸ” Checking session file: {self.session_file}")
        print(f"ğŸ” Session file exists: {os.path.exists(self.session_file)}")
        
        # Priority 1: Check local session file
        if os.path.exists(self.session_file):
            logger.info("âœ… Session file found - assuming logged in")
            print("âœ… Session file found - returning logged_in=True")
            return {
                'logged_in': True,
                'message': 'Logged in to Naver (session file found)'
            }
        
        # Priority 2: Check MongoDB session (using active user ID)
        try:
            # ğŸ”§ CRITICAL: MongoDBì—ì„œ ì§ì ‘ ì„¸ì…˜ ì¡°íšŒí•˜ì—¬ ë§Œë£Œ ì‹œê°„ í™•ì¸
            from utils.db import get_db
            db = get_db()
            if db is not None:
                session = db.naver_sessions.find_one({"_id": self.active_user_id})
                if session:
                    # ë§Œë£Œ ì‹œê°„ í™•ì¸
                    expires_at = session.get('expires_at')
                    if expires_at:
                        # ğŸ”§ FIX: expires_atì´ datetime ê°ì²´ì¸ì§€ í™•ì¸
                        if isinstance(expires_at, str):
                            # ë¬¸ìì—´ì´ë©´ íŒŒì‹±
                            try:
                                # ISO í˜•ì‹ íŒŒì‹± (Z ì œê±° í›„ UTCë¡œ ì²˜ë¦¬)
                                expires_at_str = expires_at.replace('Z', '')
                                expires_at = datetime.fromisoformat(expires_at_str)
                            except:
                                expires_at = datetime.utcnow() + timedelta(days=7)  # ê¸°ë³¸ê°’
                        
                        now = datetime.utcnow()
                        # íƒ€ì„ì¡´ ì •ë³´ê°€ ì—†ìœ¼ë©´ naive datetimeìœ¼ë¡œ ë¹„êµ (ë‘˜ ë‹¤ UTC)
                        # MongoDBì—ì„œ ê°€ì ¸ì˜¨ datetimeì€ ë³´í†µ naiveì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ë¹„êµ
                        
                        if now > expires_at:
                            print(f"âš ï¸ Session expired for user '{self.active_user_id}' (expired at: {expires_at})")
                            logger.warning(f"Session expired for user: {self.active_user_id}")
                            return {
                                'logged_in': False,
                                'message': f'ì„¸ì…˜ì´ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤ (ë§Œë£Œì¼: {expires_at.strftime("%Y-%m-%d")}). ìƒˆë¡œìš´ ì„¸ì…˜ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.',
                                'expired': True,
                                'expires_at': expires_at.isoformat()
                            }
                        else:
                            remaining_days = (expires_at - now).days
                            print(f"âœ… MongoDB session valid for user '{self.active_user_id}' (remaining: {remaining_days} days)")
                    
                    # ğŸ”§ FIX: ì¿ í‚¤ ë§Œë£Œ ì‹œê°„ë„ í™•ì¸ (ë” ì •í™•í•œ ê²€ì¦)
                    cookies = session.get('cookies', [])
                    if cookies:
                        # í•µì‹¬ ì¿ í‚¤ì˜ ë§Œë£Œ ì‹œê°„ í™•ì¸
                        critical_cookies = ['NID_AUT', 'NID_SES', 'NID_JKL']
                        all_critical_valid = True
                        
                        for cookie in cookies:
                            cookie_name = cookie.get('name', '')
                            if cookie_name in critical_cookies:
                                cookie_expiry = cookie.get('expiry')
                                if cookie_expiry:
                                    if isinstance(cookie_expiry, (int, float)):
                                        cookie_expiry_dt = datetime.fromtimestamp(cookie_expiry)
                                        if datetime.utcnow() > cookie_expiry_dt:
                                            print(f"âš ï¸ Critical cookie '{cookie_name}' expired")
                                            all_critical_valid = False
                                            break
                        
                        if not all_critical_valid:
                            print(f"âš ï¸ Some critical cookies expired for user '{self.active_user_id}'")
                            return {
                                'logged_in': False,
                                'message': 'ì„¸ì…˜ ì¿ í‚¤ê°€ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ì„¸ì…˜ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.',
                                'expired': True
                            }
                    
                    logger.info(f"âœ… MongoDB session found for user: {self.active_user_id}")
                    print(f"âœ… MongoDB session found for user '{self.active_user_id}' - returning logged_in=True")
                    return {
                        'logged_in': True,
                        'message': f'Logged in to Naver (MongoDB session found for {self.active_user_id})',
                        'active_user': self.active_user_id
                    }
        except Exception as e:
            logger.error(f"âŒ MongoDB session check error: {e}")
            print(f"âŒ MongoDB session check error: {e}")
        
        # No session found
        logger.info("âŒ No session found")
        print("âŒ No session found - returning logged_in=False")
        return {
            'logged_in': False,
            'message': 'No session found. Please login first.'
        }
    
    def get_places(self) -> List[Dict]:
        """Get list of places from Smartplace Center (with 5-minute cache)"""
        
        # ğŸ”’ Lockìœ¼ë¡œ race condition ë°©ì§€
        with self._user_lock:
            current_user_id = self.active_user_id  # Race condition ë°©ì§€
            print(f"ğŸ”’ Acquired lock for get_places() - user: {current_user_id}")
            
            # ğŸš€ Check cache first (userë³„ë¡œ í™•ì¸!)
            if current_user_id in self._places_cache and current_user_id in self._places_cache_time:
                cache_age = datetime.now() - self._places_cache_time[current_user_id]
                if cache_age < self._cache_ttl:
                    print(f"âš¡ Using cached places for user {current_user_id} (age: {int(cache_age.total_seconds())}s)")
                    logger.info(f"âš¡ Using cached places for user {current_user_id} (age: {int(cache_age.total_seconds())}s)")
                    return self._places_cache[current_user_id]
                else:
                    print(f"ğŸ”„ Cache expired for user {current_user_id} (age: {int(cache_age.total_seconds())}s), refreshing...")
                    logger.info(f"ğŸ”„ Cache expired for user {current_user_id}, refreshing...")
            
            driver = None
            driver_is_persistent = False
            
            try:
                # current_user_idëŠ” ìœ„ì—ì„œ ì´ë¯¸ ì„ ì–¸ë¨ (Lock ë‚´ë¶€)
                print(f"ğŸ“ Getting places from Smartplace Center for user: {current_user_id}")
                logger.info(f"ğŸ“ Getting places for user: {current_user_id}")
                
                # ğŸš€ PERSISTENT BROWSER: ë¨¼ì € ê¸°ì¡´ ë¸Œë¼ìš°ì € í™•ì¸
                from services.persistent_browser_manager import browser_manager
                
                driver = browser_manager.get_browser(current_user_id)
                
                if driver:
                    print(f"â™»ï¸ Reusing persistent browser for {current_user_id}")
                    driver_is_persistent = True
                else:
                    print(f"ğŸ†• Creating new browser for {current_user_id} (no persistent browser)")
                    driver = self._create_driver(headless=True, user_id=current_user_id)
                    driver_is_persistent = False
                
                # Go to business list page
                print("ğŸ  Accessing Smartplace business list...")
                driver.get('https://new.smartplace.naver.com/bizes')
                
                # ğŸ”§ CRITICAL: ì¦‰ì‹œ ì„¸ì…˜ ìœ íš¨ì„± ê²€ì¦ (ë¡œê·¸ì¸ í˜ì´ì§€ ë¦¬ë‹¤ì´ë ‰íŠ¸ í™•ì¸)
                time.sleep(2)  # ë¦¬ë‹¤ì´ë ‰íŠ¸ê°€ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì‹œê°„
                current_url = driver.current_url
                print(f"ğŸ”— Current URL after load: {current_url}")
                
                if 'nid.naver.com' in current_url or 'login' in current_url.lower():
                    print("âŒ Session expired - redirected to login page")
                    logger.error(f"Session expired for user {current_user_id}")
                    raise HTTPException(
                        status_code=401, 
                        detail=f"ë„¤ì´ë²„ ì„¸ì…˜ì´ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì„¸ì…˜ ìƒì„±ê¸°(EXE)ë¥¼ ì‚¬ìš©í•´ì„œ ìƒˆë¡œìš´ ì„¸ì…˜ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”. (User: {current_user_id})"
                    )
                
                # Wait for initial page load
                print("â³ Waiting for initial page load...")
                time.sleep(0.5)
                
                # ğŸš€ CRITICAL: Handle popup/modal that appears on first visit
                print("ğŸ” Checking for popups...")
                try:
                    # Look for common popup/modal patterns
                    popup_button_selectors = [
                        "button.Modal_btn_confirm__uQZFR",  # "í™•ì¸" button
                        "button[class*='confirm']",
                        "button[class*='close']",
                        ".dimmed button",
                        "[class*='modal'] button"
                    ]
                    
                    for selector in popup_button_selectors:
                        try:
                            popup_btn = driver.find_element(By.CSS_SELECTOR, selector)
                            if popup_btn.is_displayed():
                                print(f"  âœ… Found popup button: {selector}")
                                driver.execute_script("arguments[0].click();", popup_btn)
                                print("  âœ… Popup closed!")
                                time.sleep(1)  # Wait for popup to close
                                break
                        except:
                            continue
                except Exception as e:
                    print(f"  âš ï¸ No popup found (this is OK): {e}")
                
                # Wait for loading indicator to disappear or content to appear
                # ğŸš€ Reduced timeout from 30s to 10s
                print("â³ Waiting for content to load (up to 10 seconds)...")
                max_wait = 10
                start_time = time.time()
                content_loaded = False
                
                while time.time() - start_time < max_wait:
                    # Check if there are any links with /bizes/place/ pattern
                    try:
                        all_links = driver.find_elements(By.TAG_NAME, "a")
                        place_links = [link for link in all_links if link.get_attribute('href') and '/bizes/place/' in link.get_attribute('href')]
                        
                        if len(place_links) > 0:
                            print(f"âœ… Content loaded! Found {len(place_links)} place links")
                            content_loaded = True
                            break
                        else:
                            print(f"â³ Still loading... ({int(time.time() - start_time)}s elapsed)")
                            time.sleep(1)  # ğŸš€ Reduced from 2s to 1s
                    except:
                        time.sleep(1)
                
                if not content_loaded:
                    print("âš ï¸ Timeout waiting for content to load - trying alternative method")
                
                current_url = driver.current_url
                print(f"ğŸ”— Current URL: {current_url}")
                
                # Check if logged in
                if 'nid.naver.com' in current_url or 'login' in current_url.lower():
                    print("âŒ Not logged in")
                    raise HTTPException(status_code=401, detail="Not logged in")
                
                # Take screenshot for debugging
                screenshot_path = os.path.join(settings.data_dir, "naver_sessions", "bizes_list.png")
                driver.save_screenshot(screenshot_path)
                print(f"ğŸ“¸ Screenshot saved: {screenshot_path}")
            
                # Save page source for debugging
                page_source = driver.page_source
                page_source_file = os.path.join(settings.data_dir, "naver_sessions", "bizes_list.html")
                with open(page_source_file, 'w', encoding='utf-8') as f:
                    f.write(page_source)
                print(f"ğŸ“„ Page source saved: {page_source_file}")
                
                places = []
                
                # Method 1: Try to find place links in <a> tags
                try:
                    all_links = driver.find_elements(By.TAG_NAME, "a")
                    print(f"ğŸ“‹ Total <a> links found: {len(all_links)}")
                    
                    place_ids_found = set()
                    
                    for link in all_links:
                        href = link.get_attribute('href')
                        if href and '/bizes/place/' in href:
                            # Extract place_id from URL
                            import re
                            match = re.search(r'/bizes/place/(\d+)', href)
                            if match:
                                place_id = match.group(1)
                                if place_id not in place_ids_found:
                                    place_ids_found.add(place_id)
                                    
                                    # Try to get place name from link text or nearby element
                                    place_name = link.text.strip()
                                    if not place_name:
                                        # Try parent element
                                        try:
                                            parent = link.find_element(By.XPATH, '..')
                                            place_name = parent.text.strip()
                                        except:
                                            place_name = f"ë§¤ì¥ {place_id}"
                                    
                                    places.append({
                                        'place_id': place_id,
                                        'name': place_name,
                                        'url': f'https://new.smartplace.naver.com/bizes/place/{place_id}/reviews'
                                    })
                                    print(f"âœ… Found place from link: {place_name} (ID: {place_id})")
                    
                except Exception as e:
                    print(f"âš ï¸ Error extracting places from links: {e}")
                    logger.error(f"Error extracting places from links: {e}")
                
                # Method 2: Extract place IDs from page source using regex
                if len(places) == 0:
                    print("ğŸ” No places found in links - trying regex extraction from page source...")
                    try:
                        import re
                        # Look for place IDs in the page source
                        place_id_pattern = r'/bizes/place/(\d+)'
                        matches = re.finditer(place_id_pattern, page_source)
                        
                        place_ids_found = set()
                        for match in matches:
                            place_id = match.group(1)
                            if place_id not in place_ids_found:
                                place_ids_found.add(place_id)
                                print(f"âœ… Found place ID in page source: {place_id}")
                        
                        # For each place ID, try to find the business name
                        for place_id in place_ids_found:
                            # Try to find business name near the place ID in the source
                            # Look for patterns like: "businessName":"..." near the place ID
                            name_pattern = rf'place/{place_id}[^{{}}]*?"businessName":"([^"]+)"'
                            name_match = re.search(name_pattern, page_source)
                            
                            if name_match:
                                place_name = name_match.group(1)
                            else:
                                # Alternative: look for any Korean text near place ID
                                context_pattern = rf'place/{place_id}[^<>]{{0,200}}>([ê°€-í£\s]+)<'
                                context_match = re.search(context_pattern, page_source)
                                if context_match:
                                    place_name = context_match.group(1).strip()
                                else:
                                    place_name = f"ë§¤ì¥ {place_id}"
                            
                            places.append({
                                'place_id': place_id,
                                'name': place_name,
                                'url': f'https://new.smartplace.naver.com/bizes/place/{place_id}/reviews'
                            })
                            print(f"âœ… Extracted place: {place_name} (ID: {place_id})")
                    
                    except Exception as e:
                        print(f"âš ï¸ Error extracting places from page source: {e}")
                        logger.error(f"Error extracting places from page source: {e}")
                
                print(f"ğŸ“Š Total places found: {len(places)}")
                logger.info(f"âœ… Found {len(places)} places")
                
                # ğŸš€ Save to cache (userë³„ë¡œ ì €ì¥!)
                self._places_cache[current_user_id] = places
                self._places_cache_time[current_user_id] = datetime.now()
                print(f"ğŸ’¾ Cached {len(places)} places for user {current_user_id} (5 minutes)")
                
                return places
                
            except Exception as e:
                print(f"âŒ Error getting places: {e}")
                logger.error(f"Error getting places: {e}")
                raise HTTPException(status_code=500, detail=f"Error getting places: {str(e)}")
                
            finally:
                # ğŸš€ PERSISTENT BROWSER: persistent browserëŠ” ë‹«ì§€ ì•ŠìŒ!
                if driver and not driver_is_persistent:
                    driver.quit()
                    print("ğŸ”’ Closed temporary browser")
                elif driver and driver_is_persistent:
                    print("â™»ï¸ Keeping persistent browser alive")
    
    def get_reviews(self, place_id: str, page: int = 1, page_size: int = 20, filter_type: str = 'all', load_count: int = 300) -> List[Dict]:
        """Get reviews for a place from Smartplace Center (BATCH LOADING + CACHE)
        
        New Strategy: Load specified number of reviews, then filter on frontend
        
        Args:
            place_id: Naver place ID
            page: Page number
            page_size: Reviews per page
            filter_type: 'all' (frontend filters)
            load_count: Number of reviews to load (50/150/300/500/1000)
        """
        print(f"ğŸ“ Getting reviews for place: {place_id} (page {page}, size {page_size}, load_count={load_count})")
        
        # ğŸš€ CRITICAL FIX: Initialize progress BEFORE cache check!
        # This ensures progress is always visible, even when serving from cache
        if place_id not in self._loading_progress or self._loading_progress[place_id]['status'] != 'loading':
            print(f"ğŸ”„ Initializing progress for {place_id}")
            self._loading_progress[place_id] = {
                'status': 'loading',
                'count': 0,
                'message': 'ğŸš€ ì‹œì‘ ì¤‘...',
                'timestamp': datetime.now()
            }
        
        # ğŸš€ STEP 1: Check Cache (Include load_count in key)
        cache_key = f"{place_id}:all:{load_count}"  # Cache by place_id and load_count
        if cache_key in self._reviews_cache:
            cache_entry = self._reviews_cache[cache_key]
            cache_age = datetime.now() - cache_entry['time']
            
            if cache_age < self._reviews_cache_ttl:
                all_cached_reviews = cache_entry['data']
                total_count = cache_entry['total']
                
                start_idx = (page - 1) * page_size
                end_idx = start_idx + page_size
                
                # ğŸš€ SMART EXPANSION: If we need more data than cached, load more!
                if end_idx > len(all_cached_reviews) and len(all_cached_reviews) < total_count:
                    print(f"ğŸ“š Need more data: Have {len(all_cached_reviews)}, Need {end_idx}, Total {total_count}")
                    print(f"ğŸ”„ Expanding cache by loading 200 more reviews...")
                    # Continue to load more (don't return, fall through to loading logic)
                elif len(all_cached_reviews) > 0:
                    print(f"âš¡ Using cached reviews (Items {len(all_cached_reviews)}, Age {int(cache_age.total_seconds())}s)")
                    
                    # ğŸš€ Update progress to show cache hit
                    self._loading_progress[place_id].update({
                        'status': 'completed',
                        'count': len(all_cached_reviews),
                        'message': f'âš¡ ìºì‹œì—ì„œ ë¡œë“œ ì™„ë£Œ ({len(all_cached_reviews)}ê°œ)',
                        'timestamp': datetime.now()
                    })
                    
                    # Return ALL reviews (frontend will paginate)
                    return {
                        'reviews': all_cached_reviews,  # Return ALL (not paginated)
                        'total': total_count
                    }
                else:
                    print(f"ğŸ”„ Cache hit but empty. Refreshing just in case...")
            else:
                print(f"â° Cache expired (Age {int(cache_age.total_seconds())}s). Refreshing...")
        
        # ğŸš€ STEP 2: Fetch NEW data (User-specified count)
        # Check if we're expanding existing cache
        existing_reviews = []
        if cache_key in self._reviews_cache:
            existing_reviews = self._reviews_cache[cache_key]['data']
            print(f"ğŸ“¦ Expanding cache: Currently have {len(existing_reviews)} reviews")
        
        # ğŸš€ USER CHOICE: Load exactly what user requested
        TARGET_LOAD_COUNT = load_count
        
        driver = None
        driver_is_persistent = False
        current_user_id = self.active_user_id  # race condition ë°©ì§€
        
        try:
            # ğŸš€ CRITICAL: Initialize progress tracking BEFORE anything
            print(f"ğŸ”„ Initializing progress tracking for {place_id}, user: {current_user_id}")
            self._loading_progress[place_id] = {
                'status': 'loading',
                'count': 0,
                'message': 'ğŸš€ ë¸Œë¼ìš°ì € ì‹œì‘ ì¤‘...',
                'timestamp': datetime.now()
            }
            logger.info(f"Progress initialized: {self._loading_progress[place_id]}")
            
            # ğŸš€ PERSISTENT BROWSER: ë¨¼ì € ê¸°ì¡´ ë¸Œë¼ìš°ì € í™•ì¸
            from services.persistent_browser_manager import browser_manager
            
            driver = browser_manager.get_browser(current_user_id)
            
            if driver:
                print(f"â™»ï¸ Reusing persistent browser for {current_user_id}")
                driver_is_persistent = True
            else:
                print(f"ğŸ†• Creating new browser for {current_user_id} (no persistent browser)")
                driver = self._create_driver(headless=True, user_id=current_user_id)
                driver_is_persistent = False
            
            # Update progress
            self._loading_progress[place_id]['message'] = 'ğŸ” ì„¸ì…˜ ë¡œë”© ì¤‘...'
            print(f"Progress: {self._loading_progress[place_id]['message']}")
            reviews_url = f'https://new.smartplace.naver.com/bizes/place/{place_id}/reviews?menu=visitor'
            print(f"ğŸ”— Accessing: {reviews_url}")
            self._loading_progress[place_id]['message'] = 'ğŸ“„ ë¦¬ë·° í˜ì´ì§€ ì ‘ì† ì¤‘...'
            driver.get(reviews_url)
            
            print("â³ Waiting for reviews page to load...")
            self._loading_progress[place_id]['message'] = 'â³ í˜ì´ì§€ ë¡œë”© ì¤‘...'
            time.sleep(2)
            
            # Handle popup
            try:
                popup_btn = driver.find_element(By.CSS_SELECTOR, "button.Modal_btn_confirm__uQZFR")
                if popup_btn.is_displayed():
                    driver.execute_script("arguments[0].click();", popup_btn)
                    time.sleep(1)
            except:
                pass
            
            # ğŸš€ NEW STRATEGY: Skip UI filter, load ALL reviews directly
            # This is more stable and efficient than trying to click filters
            print("ğŸ“œ Loading ALL reviews (ì‘ì„±ì¼ìˆœ)...")
            target_display = "ì „ì²´" if TARGET_LOAD_COUNT >= 9999 else f"{TARGET_LOAD_COUNT}ê°œ"
            self._loading_progress[place_id].update({
                'status': 'loading',
                'count': 0,
                'message': f'ğŸ“œ ìŠ¤í¬ë¡¤ ì¤€ë¹„ ì¤‘... (ëª©í‘œ: {target_display})',
                'timestamp': datetime.now()
            })
            print(f"Progress before scroll: {self._loading_progress[place_id]}")
            
            # ğŸš€ STEP 3: Scroll Logic (Smart Adaptive Loading)
            print(f"ğŸ“œ Smart batch loading (Target: {TARGET_LOAD_COUNT})...")
            self._loading_progress[place_id]['message'] = f'ğŸ“œ ìŠ¤í¬ë¡¤ ì‹œì‘! (ëª©í‘œ: {target_display})'
            print(f"Progress at scroll start: {self._loading_progress[place_id]}")
            
            last_count = 0
            no_change = 0
            skip_ratio = None  # ìŠ¤í‚µ ë¹„ìœ¨ (ë™ì  ì¶”ì •)
            estimated_valid_count = 0  # ì¶”ì •ëœ ìœ íš¨ ë¦¬ë·° ê°œìˆ˜
            sample_parsed = False  # ìƒ˜í”Œ íŒŒì‹± ì™„ë£Œ ì—¬ë¶€
            
            # ğŸš€ ìµœì í™”: ì´ˆê¸° ëª©í‘œëŠ” ë³´ìˆ˜ì ìœ¼ë¡œ ì„¤ì • (ë‚˜ì¤‘ì— ì¡°ì •)
            INITIAL_TARGET = int(TARGET_LOAD_COUNT * 1.8)  # 2.5 â†’ 1.8ë¡œ ê°ì†Œ (ì´ˆê¸°)
            ADJUSTED_TARGET = INITIAL_TARGET
            
            # Adjust scroll attempts based on target
            max_scrolls = 50 if TARGET_LOAD_COUNT <= 50 else \
                         100 if TARGET_LOAD_COUNT <= 150 else \
                         150 if TARGET_LOAD_COUNT <= 300 else \
                         250 if TARGET_LOAD_COUNT <= 500 else \
                         400 if TARGET_LOAD_COUNT <= 1000 else \
                         800  # For "all" (9999)
            
            for i in range(max_scrolls):
                try:
                    lis = driver.find_elements(By.TAG_NAME, "li")
                    current_count = len(lis)
                    
                    if current_count > last_count:
                        # Print every change
                        print(f"  ğŸ“ˆ Loaded {current_count} reviews...")
                        
                        # ğŸš€ ALWAYS update progress (every single change for real-time feel)
                        message = f'ğŸ“ˆ {current_count}ê°œ ë¦¬ë·° ë¡œë“œë¨...'
                        if estimated_valid_count > 0:
                            message += f' (ì¶”ì • ìœ íš¨: {estimated_valid_count}ê°œ)'
                        self._loading_progress[place_id].update({
                            'status': 'loading',
                            'count': current_count,
                            'message': message,
                            'timestamp': datetime.now()
                        })
                        
                        last_count = current_count
                        no_change = 0
                    else:
                        no_change += 1
                    
                    # ğŸš€ NEW: ìƒ˜í”Œ íŒŒì‹±ìœ¼ë¡œ ìŠ¤í‚µ ë¹„ìœ¨ ì¶”ì • (15ê°œ ì´ìƒ ë¡œë“œ ì‹œ 1íšŒë§Œ, ë” ë¹ ë¥´ê²Œ)
                    if not sample_parsed and current_count >= 15:
                        print(f"  ğŸ” ìƒ˜í”Œ íŒŒì‹± ì‹œì‘ (ìŠ¤í‚µ ë¹„ìœ¨ ì¶”ì •, {current_count}ê°œ ì¤‘)...")
                        try:
                            sample_size = min(15, current_count)  # ì²˜ìŒ 15ê°œ ìƒ˜í”Œ (ë” ë¹ ë¥´ê²Œ)
                            valid_count = 0
                            
                            for li in lis[:sample_size]:
                                try:
                                    author = li.find_element(By.CLASS_NAME, "pui__JiVbY3").text.strip()
                                    if author and author != "ìµëª…" and "ê°€ì´ë“œ" not in author:
                                        valid_count += 1
                                except:
                                    pass
                            
                            if sample_size > 0:
                                skip_ratio = 1.0 - (valid_count / sample_size)
                                # ìŠ¤í‚µ ë¹„ìœ¨ ê¸°ë°˜ìœ¼ë¡œ ëª©í‘œ ì¬ê³„ì‚° (15% ì—¬ìœ ë§Œ)
                                if skip_ratio > 0:
                                    ADJUSTED_TARGET = int(TARGET_LOAD_COUNT / (1.0 - skip_ratio) * 1.15)  # 15% ì—¬ìœ 
                                    print(f"  âœ… ìƒ˜í”Œ ë¶„ì„: {valid_count}/{sample_size} ìœ íš¨ (ìŠ¤í‚µ ë¹„ìœ¨: {skip_ratio:.1%})")
                                    print(f"  ğŸ¯ ëª©í‘œ ì¡°ì •: {INITIAL_TARGET} â†’ {ADJUSTED_TARGET}ê°œ (íš¨ìœ¨ì !)")
                                else:
                                    ADJUSTED_TARGET = int(TARGET_LOAD_COUNT * 1.1)  # ìŠ¤í‚µì´ ê±°ì˜ ì—†ìœ¼ë©´ 10%ë§Œ ì—¬ìœ 
                                    print(f"  âœ… ìƒ˜í”Œ ë¶„ì„: ìŠ¤í‚µ ê±°ì˜ ì—†ìŒ, ëª©í‘œ: {ADJUSTED_TARGET}ê°œ")
                            
                            sample_parsed = True
                        except Exception as e:
                            print(f"  âš ï¸ ìƒ˜í”Œ íŒŒì‹± ì˜¤ë¥˜: {e}, ê¸°ë³¸ ëª©í‘œ ì‚¬ìš©")
                    
                    # ğŸš€ ë™ì  ëª©í‘œ í™•ì¸ (ì¶”ì •ëœ ìŠ¤í‚µ ë¹„ìœ¨ ë°˜ì˜, ë§¤ ìŠ¤í¬ë¡¤ë§ˆë‹¤ í™•ì¸)
                    if skip_ratio is not None and current_count >= 10:
                        # í˜„ì¬ê¹Œì§€ì˜ ìœ íš¨ ë¦¬ë·° ê°œìˆ˜ ì¶”ì •
                        estimated_valid_count = int(current_count * (1.0 - skip_ratio))
                        
                        # ëª©í‘œì— ë„ë‹¬í–ˆìœ¼ë©´ ì¡°ê¸° ì¢…ë£Œ
                        if estimated_valid_count >= TARGET_LOAD_COUNT:
                            print(f"  âœ… ì¶”ì • ìœ íš¨ ë¦¬ë·° {estimated_valid_count}ê°œ ë„ë‹¬! (ëª©í‘œ: {TARGET_LOAD_COUNT}ê°œ)")
                            print(f"     ì¡°ê¸° ì¢…ë£Œë¡œ ì‹œê°„ ì ˆì•½ (ë¶ˆí•„ìš”í•œ ìŠ¤í¬ë¡¤ {ADJUSTED_TARGET - current_count}ê°œ ìƒëµ)")
                            break
                    
                    # ê¸°ì¡´ ëª©í‘œ ë„ë‹¬ í™•ì¸
                    if current_count >= ADJUSTED_TARGET:
                        print(f"  âœ… Reached adjusted target {ADJUSTED_TARGET} (raw count, before filtering)")
                        print(f"     Expected after filtering: ~{TARGET_LOAD_COUNT} reviews")
                        break
                        
                    # ğŸ”§ FIX: ë” ë§ì€ ì‹œë„ í—ˆìš© (5 â†’ 10)
                    if no_change >= 10:  # 5 â†’ 10ìœ¼ë¡œ ì¦ê°€
                        print(f"  âš ï¸ No more content loading after {no_change} attempts.")
                        # ëª©í‘œ ê°œìˆ˜ì— ë„ë‹¬í•˜ì§€ ëª»í–ˆì§€ë§Œ ë” ì´ìƒ ë¡œë“œí•  ê²ƒì´ ì—†ìœ¼ë©´ ì¤‘ë‹¨
                        if current_count < ADJUSTED_TARGET:
                            print(f"  âš ï¸ Warning: Only loaded {current_count} items, target was {ADJUSTED_TARGET}")
                        break
                    
                    # ğŸš€ FIX: Use scrollIntoView on the LAST element
                    if lis:
                        driver.execute_script("arguments[0].scrollIntoView(true);", lis[-1])
                    else:
                        driver.execute_script("window.scrollBy(0, 1000);")
                        
                    time.sleep(0.5)  # Wait for render
                    
                except Exception as e:
                    print(f"  âš ï¸ Scroll error: {e}")
                    break
            
            # ğŸš€ STEP 4: Parse Data
            print(f"ğŸ” Parsing {last_count} <li> elements...")
            self._loading_progress[place_id]['message'] = f'ğŸ“ {last_count}ê°œ ë¦¬ë·° íŒŒì‹± ì¤‘...'
            all_reviews = []
            
            # ğŸ”§ DEBUG: ìŠ¤í‚µ ì¹´ìš´í„°
            skip_reasons = {
                'no_author': 0,
                'anonymous': 0,
                'guide': 0,
                'guide_message': 0,
                'parse_error': 0
            }
            
            # Get total count first
            total_count = 0
            try:
                import re
                txt = driver.find_element(By.TAG_NAME, 'body').text
                m = re.search(r'ì „ì²´\s*(\d+)', txt)
                if m: total_count = int(m.group(1))
            except: pass
            
            lis = driver.find_elements(By.TAG_NAME, "li")
            total_li_count = len(lis)
            
            # ğŸš€ íŒŒì‹± ì¤‘ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ ì¹´ìš´í„°
            parsed_count = 0
            update_interval = max(1, total_li_count // 20)  # 20ë²ˆ ì •ë„ ì—…ë°ì´íŠ¸
            
            for idx, li in enumerate(lis):
                try:
                    # Author
                    try:
                        author = li.find_element(By.CLASS_NAME, "pui__JiVbY3").text.strip()
                    except:
                        skip_reasons['no_author'] += 1
                        continue # Skip if no author structure
                        
                    # Date
                    date = "ë‚ ì§œ ì—†ìŒ"
                    try:
                        d_elems = li.find_elements(By.CLASS_NAME, "pui__m7nkds")
                        for d in d_elems:
                            if re.search(r'20\d{2}\.', d.text):
                                date = d.text.strip()
                                break
                    except: pass
                    
                    # Content (Relaxed filter)
                    content = ""
                    try:
                        # Click 'more' if exists
                        try:
                            btn = li.find_element(By.CLASS_NAME, "pui__wFzIYl")
                            driver.execute_script("arguments[0].click();", btn)
                        except: pass
                        
                        content = li.find_element(By.CLASS_NAME, "pui__vn15t2").text.strip()
                    except: 
                        content = "" # Allow empty content (Issue #1 fix)

                    # Filter: Valid Author?
                    if not author:
                        skip_reasons['no_author'] += 1
                        continue
                    if author == "ìµëª…":
                        skip_reasons['anonymous'] += 1
                        continue
                    if "ê°€ì´ë“œ" in author:
                        skip_reasons['guide'] += 1
                        continue
                    
                    # Filter: Guide message in content?
                    if "ë‹µê¸€ ì˜ ë‹¤ëŠ” ë°©ë²•" in content:
                        skip_reasons['guide_message'] += 1
                        continue

                    # Reply
                    reply_text = None
                    reply_date = None
                    try:
                        reply_elem = li.find_element(By.CLASS_NAME, "pui__GbW8H7")
                        full_reply = reply_elem.text
                        
                        # Extract date from reply
                        rd_match = re.search(r'20\d{2}\.\s*\d{1,2}\.\s*\d{1,2}', full_reply)
                        if rd_match:
                            reply_date = rd_match.group(0)
                        
                        reply_text = full_reply
                    except: pass

                    # ID Generation
                    unique_str = f"{author}-{date}-{content[:30]}"
                    rid = hashlib.md5(unique_str.encode()).hexdigest()[:8]
                    
                    # ğŸš€ NEW STRATEGY: Load ALL reviews, filter on frontend
                    # No server-side filtering - this is more stable and efficient
                    
                    all_reviews.append({
                        'review_id': f"naver-{place_id}-{rid}",
                        'place_id': place_id,
                        'author': author,
                        'date': date,
                        'content': content,
                        'has_reply': bool(reply_text),
                        'reply': reply_text,
                        'reply_date': reply_date
                    })
                    
                    # ğŸš€ íŒŒì‹± ì¤‘ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (ì‹¤ì œ ìœ íš¨í•œ ë¦¬ë·° ê°œìˆ˜)
                    parsed_count += 1
                    if parsed_count % update_interval == 0 or parsed_count == 1:
                        self._loading_progress[place_id].update({
                            'status': 'loading',
                            'count': parsed_count,  # ì‹¤ì œ íŒŒì‹±ëœ ë¦¬ë·° ê°œìˆ˜
                            'message': f'ğŸ“ {parsed_count}ê°œ ë¦¬ë·° íŒŒì‹± ì¤‘... ({idx+1}/{total_li_count})',
                            'timestamp': datetime.now()
                        })
                    
                except Exception as parse_err:
                    skip_reasons['parse_error'] += 1
                    continue

            # ğŸ”§ DEBUG: ìŠ¤í‚µ í†µê³„ ì¶œë ¥
            total_skipped = sum(skip_reasons.values())
            print(f"ğŸ“Š Parsing complete: {len(all_reviews)} valid reviews, {total_skipped} skipped")
            if total_skipped > 0:
                print(f"   Skip breakdown:")
                for reason, count in skip_reasons.items():
                    if count > 0:
                        print(f"      - {reason}: {count}")
            
            # ğŸš€ MERGE with existing cache if expanding
            if existing_reviews:
                print(f"ğŸ”— Merging {len(all_reviews)} new reviews with {len(existing_reviews)} existing...")
                # Combine existing + new
                combined_reviews = existing_reviews + all_reviews
            else:
                combined_reviews = all_reviews
            
            # Deduplicate
            unique_reviews = []
            seen = set()
            for r in combined_reviews:
                if r['review_id'] not in seen:
                    seen.add(r['review_id'])
                    unique_reviews.append(r)
            
            # ğŸš€ ROBUST SORTING by date (newest first)
            def parse_review_date(date_str):
                """Parse Korean date format: '2025. 12. 9' or '2025. 9. 8(í™”)'"""
                try:
                    # Remove day of week if present: '2025. 12. 9(í™”)' -> '2025. 12. 9'
                    date_str = re.sub(r'\([ì›”í™”ìˆ˜ëª©ê¸ˆí† ì¼]\)', '', date_str).strip()
                    # Remove extra spaces and dots: '2025. 12. 9' -> '2025-12-09'
                    parts = [p.strip() for p in date_str.replace('.', '').split() if p.strip()]
                    if len(parts) >= 3:
                        year, month, day = parts[0], parts[1].zfill(2), parts[2].zfill(2)
                        return f"{year}-{month}-{day}"
                except:
                    pass
                return "1900-01-01"  # Fallback for unparseable dates
            
            try:
                unique_reviews.sort(key=lambda x: parse_review_date(x['date']), reverse=True)
                print(f"âœ… Sorted {len(unique_reviews)} reviews by date (newest first)")
            except Exception as e:
                print(f"âš ï¸ Sort warning: {e}")
            
            # ğŸ”§ FIX: í•„í„°ë§ í›„ ê°œìˆ˜ í™•ì¸ ë° ê²½ê³ 
            if len(unique_reviews) < TARGET_LOAD_COUNT:
                shortage = TARGET_LOAD_COUNT - len(unique_reviews)
                print(f"âš ï¸ WARNING: Requested {TARGET_LOAD_COUNT} reviews, but only {len(unique_reviews)} valid reviews found after filtering!")
                print(f"   Missing: {shortage} reviews (likely filtered out as ìµëª…/ê°€ì´ë“œ)")
                logger.warning(f"Review shortage: Requested {TARGET_LOAD_COUNT}, got {len(unique_reviews)}")
            
            # ğŸš€ STEP 5: Update Cache (Specific to filter)
            self._reviews_cache[cache_key] = {
                'data': unique_reviews,
                'time': datetime.now(),
                'total': total_count if total_count > 0 else len(unique_reviews)
            }
            print(f"ğŸ’¾ Cached {len(unique_reviews)} reviews for {cache_key}")
            
            # ğŸš€ Return ALL reviews (frontend will handle filtering + pagination)
            # This allows filter to work across all loaded reviews
            
            # ğŸš€ Mark as completed
            self._loading_progress[place_id] = {
                'status': 'completed',
                'count': len(unique_reviews),
                'message': f'âœ… {len(unique_reviews)}ê°œ ë¦¬ë·° ë¡œë“œ ì™„ë£Œ!',
                'timestamp': datetime.now()
            }
            
            return {
                'reviews': unique_reviews,  # Return ALL reviews (not paginated)
                'total': self._reviews_cache[cache_key]['total']
            }
        
        except Exception as e:
            print(f"âŒ Error: {e}")
            # ğŸš€ Mark as error
            self._loading_progress[place_id] = {
                'status': 'error',
                'count': 0,
                'message': f'âŒ ì˜¤ë¥˜: {str(e)[:50]}',
                'timestamp': datetime.now()
            }
            raise HTTPException(status_code=500, detail=str(e))
        
        finally:
            # ğŸš€ PERSISTENT BROWSER: persistent browserëŠ” ë‹«ì§€ ì•ŠìŒ!
            if driver and not driver_is_persistent:
                driver.quit()
                print("ğŸ”’ Closed temporary browser")
            elif driver and driver_is_persistent:
                print("â™»ï¸ Keeping persistent browser alive")
    
    def post_reply_by_composite(self, place_id: str, author: str, date: str, content: str, reply_text: str, user_id: str = None, expected_count: int = 50) -> Dict:
        """
        ì‘ì„±ì + ë‚ ì§œ + ë‚´ìš© 3ì¤‘ ë§¤ì¹­ìœ¼ë¡œ ë‹µê¸€ ê²Œì‹œ (ê°€ì¥ í™•ì‹¤í•œ ë°©ë²•)
        expected_countë§Œí¼ ë¦¬ë·°ë¥¼ ë Œë”ë§í•˜ì—¬ ì°¾ê¸°
        """
        import re
        
        # ğŸ”’ í˜„ì¬ user_id ë¯¸ë¦¬ ì €ì¥ (race condition ë°©ì§€)
        if user_id:
            self.set_active_user(user_id)
        current_user_id = self.active_user_id
        
        driver = None
        driver_is_persistent = False
        
        try:
            print(f"ğŸ’¬ Posting reply to: {author} ({date}) for user: {current_user_id}")
            print(f"ğŸ¯ Target: {expected_count} reviews to render")
            
            # ğŸš€ PERSISTENT BROWSER: ë¨¼ì € ê¸°ì¡´ ë¸Œë¼ìš°ì € í™•ì¸
            from services.persistent_browser_manager import browser_manager
            
            driver = browser_manager.get_browser(current_user_id)
            
            if driver:
                print(f"â™»ï¸ Reusing persistent browser for {current_user_id}")
                driver_is_persistent = True
            else:
                print(f"ğŸ†• Creating new browser for {current_user_id} (no persistent browser)")
                driver = self._create_driver(headless=True, user_id=current_user_id)
                driver_is_persistent = False
            
            # Go to reviews page with "ë¯¸ë“±ë¡" filter (hasReply=false)
            # ğŸš€ URL íŒŒë¼ë¯¸í„°ë¡œ ë¯¸ë‹µê¸€ ë¦¬ë·°ë§Œ í•„í„°ë§ (UI ì¡°ì‘ë³´ë‹¤ í›¨ì”¬ ì•ˆì •ì !)
            reviews_url = f'https://new.smartplace.naver.com/bizes/place/{place_id}/reviews?menu=visitor&hasReply=false'
            print(f"ğŸ”— Opening: {reviews_url}")
            print(f"   âœ… Filter: hasReply=false (unreplied reviews only)")
            driver.get(reviews_url)
            time.sleep(3)
            
            # Handle popup
            try:
                popup_btn = driver.find_element(By.CSS_SELECTOR, "button.Modal_btn_confirm__uQZFR")
                if popup_btn.is_displayed():
                    driver.execute_script("arguments[0].click();", popup_btn)
                    time.sleep(1)
            except:
                pass
            
            # ğŸš€ URL íŒŒë¼ë¯¸í„°ë¡œ í•„í„°ê°€ ì´ë¯¸ ì ìš©ë¨ (hasReply=false)
            # UI ì¡°ì‘ ë¶ˆí•„ìš”! í›¨ì”¬ ë¹ ë¥´ê³  ì•ˆì •ì 
            print("âœ… Filter applied via URL parameter (hasReply=false)")
            
            # ğŸš€ ì ì§„ì  ë¡œë”© ì „ëµ: 10ê°œì”© ë Œë”ë§í•˜ë©´ì„œ ì°¾ê¸° (ì†ë„ í–¥ìƒ!)
            print(f"ğŸš€ Progressive loading: Searching in chunks of 10 reviews...")
            
            # ğŸ”§ ë‚ ì§œì—ì„œ ìš”ì¼ ì œê±° (ë¹„êµ ì „) - í•œ ë²ˆë§Œ ì‹¤í–‰
            date_clean = re.sub(r'\([^)]*\)', '', date).strip()
            author_prefix = author[:min(3, len(author))]
            print(f"ğŸ¯ Target: author='{author_prefix}...', date='{date_clean}'")
            
            scroll_count = 0
            max_scrolls = 20
            target_review = None
            batch_size = 10  # 10ê°œì”© ì²˜ë¦¬
            last_check_count = 0  # ë§ˆì§€ë§‰ìœ¼ë¡œ í™•ì¸í•œ ë¦¬ë·° ê°œìˆ˜
            consecutive_no_load = 0  # ğŸ”§ ì—°ì†ìœ¼ë¡œ ìƒˆ ë¦¬ë·°ê°€ ë¡œë“œë˜ì§€ ì•Šì€ íšŸìˆ˜
            
            while scroll_count < max_scrolls and not target_review:
                # í˜„ì¬ í˜ì´ì§€ì˜ ëª¨ë“  ìš”ì†Œ ê°€ì ¸ì˜¤ê¸°
                all_lis = driver.find_elements(By.TAG_NAME, "li")
                
                # ìœ íš¨í•œ ë¦¬ë·°ë§Œ í•„í„°ë§ (ì‘ì„±ì ìš”ì†Œê°€ ìˆëŠ” ê²ƒ)
                valid_reviews = []
                for li in all_lis:
                    try:
                        li.find_element(By.CLASS_NAME, "pui__JiVbY3")
                        valid_reviews.append(li)
                    except:
                        continue
                
                current_count = len(valid_reviews)
                newly_loaded = current_count - last_check_count
                
                print(f"  ğŸ“¦ Batch {scroll_count + 1}: {current_count} total reviews ({newly_loaded} newly loaded)")
                
                # ğŸ”§ ì—°ì† 0ê°œ ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸
                if newly_loaded == 0:
                    consecutive_no_load += 1
                else:
                    consecutive_no_load = 0  # ë¦¬ì…‹
                
                # ğŸ” ìƒˆë¡œ ë¡œë“œëœ ë¦¬ë·°ì—ì„œë§Œ ê²€ìƒ‰ (íš¨ìœ¨ì !)
                search_start_idx = max(0, last_check_count)
                search_reviews = valid_reviews[search_start_idx:]
                
                if search_reviews:
                    print(f"  ğŸ” Searching in reviews [{search_start_idx}:{current_count}]...")
                    
                    # ğŸ¯ íƒ€ê²Ÿ ë¦¬ë·° ì°¾ê¸° (ì‘ì„±ì + ë‚ ì§œ + ë‚´ìš© ë§¤ì¹­)
                    for idx, li in enumerate(search_reviews):
                        try:
                            # ì‘ì„±ì ê°€ì ¸ì˜¤ê¸°
                            try:
                                li_author = li.find_element(By.CLASS_NAME, "pui__JiVbY3").text.strip()
                            except:
                                continue
                            
                            # ë‚ ì§œ ê°€ì ¸ì˜¤ê¸°
                            li_date = ""
                            try:
                                d_elems = li.find_elements(By.CLASS_NAME, "pui__m7nkds")
                                for d in d_elems:
                                    if re.search(r'20\d{2}\.', d.text):
                                        li_date = d.text.strip()
                                        break
                            except:
                                continue
                            
                            # ğŸš€ ì‘ì„±ì + ë‚ ì§œ ë§¤ì¹­ (ìš”ì¼ ì œê±°, ì‘ì„±ì ë¶€ë¶„ ì¼ì¹˜)
                            li_date_clean = re.sub(r'\([^)]*\)', '', li_date).strip()
                            
                            # ì‘ì„±ì ë§¤ì¹­ (ì• 3ê¸€ì) - author_prefixëŠ” ìœ„ì—ì„œ ì´ë¯¸ ì •ì˜ë¨
                            author_match = li_author.startswith(author_prefix)
                            date_match = li_date_clean == date_clean
                            
                            # ë‚´ìš© ë§¤ì¹­ (ìˆìœ¼ë©´)
                            content_match = True
                            if content and len(content) > 10:
                                try:
                                    li_content = li.find_element(By.CLASS_NAME, "pui__vn15t2").text.strip()
                                    content_match = content[:50] in li_content[:100]
                                except:
                                    content_match = True
                            
                            # ğŸ¯ ë§¤ì¹­ ì„±ê³µ!
                            if author_match and date_match and content_match:
                                print(f"  âœ… Found at position {search_start_idx + idx}: '{li_author}' ({li_date_clean})")
                                target_review = li
                                break
                                
                        except Exception as e:
                            # ê°œë³„ ë¦¬ë·° íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê³„ì† ì§„í–‰ (ì—ëŸ¬ ë°©ì§€)
                            continue
                    
                    if target_review:
                        print(f"ğŸ‰ Target review found after {scroll_count + 1} batches!")
                        break
                
                # ğŸš€ ëª©í‘œ ê°œìˆ˜ì— ë„ë‹¬í–ˆê±°ë‚˜ ë” ì´ìƒ ë¡œë“œí•  ê²ƒì´ ì—†ìœ¼ë©´ ì¤‘ë‹¨
                if current_count >= expected_count:
                    print(f"  â„¹ï¸ Reached expected count: {current_count} >= {expected_count}")
                    if not target_review:
                        print(f"  âš ï¸ Target not found yet, searching all loaded reviews...")
                        # ì „ì²´ ë‹¤ì‹œ ê²€ìƒ‰ (í˜¹ì‹œ ë†“ì¹œ ê²ƒì´ ìˆì„ ìˆ˜ ìˆìŒ)
                        break
                    else:
                        break
                
                # ğŸ”§ FIX: expected_countë¥¼ ê³ ë ¤í•˜ì—¬ ì¤‘ë‹¨ ê²°ì •
                # ì—°ì† 3ë²ˆ ìƒˆ ë¦¬ë·°ê°€ ì—†ê³ , ìŠ¤í¬ë¡¤ì„ ì¶©ë¶„íˆ ì‹œë„í–ˆìœ¼ë©´ ì¤‘ë‹¨
                if consecutive_no_load >= 3 and scroll_count >= 5:
                    if current_count < expected_count:
                        print(f"  âš ï¸ Loaded only {current_count}/{expected_count}, but no more reviews available")
                    else:
                        print(f"  â„¹ï¸ No new reviews loaded for {consecutive_no_load} attempts, stopping scroll")
                    break
                
                # ë‹¤ìŒ ë°°ì¹˜ë¥¼ ìœ„í•´ ìŠ¤í¬ë¡¤
                last_check_count = current_count
                driver.execute_script("window.scrollBy(0, 1500);")
                time.sleep(1.5)  # ğŸ”§ 1ì´ˆ â†’ 1.5ì´ˆë¡œ ì¦ê°€ (ë„¤ì´ë²„ ë™ì  ë¡œë”© ëŒ€ê¸°)
                scroll_count += 1
            
            # ğŸ” íƒ€ê²Ÿì„ ëª» ì°¾ì•˜ìœ¼ë©´ ì „ì²´ ë‹¤ì‹œ ê²€ìƒ‰ (ì•ˆì „ì¥ì¹˜)
            if not target_review:
                print(f"âš ï¸ Not found in progressive search, searching all {len(valid_reviews)} reviews...")
                
                # ë§¨ ìœ„ë¡œ ìŠ¤í¬ë¡¤
                driver.execute_script("window.scrollTo(0, 0);")
                time.sleep(1)
                
                all_lis = driver.find_elements(By.TAG_NAME, "li")
                print(f"ğŸ“‹ Found {len(all_lis)} total elements on page")
                
                for li in all_lis:
                    try:
                        # ì‘ì„±ì ê°€ì ¸ì˜¤ê¸° (í•œêµ­ì–´, *, ì˜ì–´ ëª¨ë‘ ì²˜ë¦¬)
                        try:
                            li_author = li.find_element(By.CLASS_NAME, "pui__JiVbY3").text.strip()
                        except:
                            continue
                        
                        # ë‚ ì§œ ê°€ì ¸ì˜¤ê¸°
                        li_date = ""
                        try:
                            d_elems = li.find_elements(By.CLASS_NAME, "pui__m7nkds")
                            for d in d_elems:
                                if re.search(r'20\d{2}\.', d.text):
                                    li_date = d.text.strip()
                                    break
                        except:
                            continue
                        
                        # ğŸš€ ì‘ì„±ì + ë‚ ì§œ ë§¤ì¹­ (ìš”ì¼ ì œê±°) - ë³€ìˆ˜ëŠ” ì´ë¯¸ ìœ„ì—ì„œ ì •ì˜ë¨
                        li_date_clean = re.sub(r'\([^)]*\)', '', li_date).strip()
                        
                        # ğŸš€ 3ì¤‘ ë§¤ì¹­: ì‘ì„±ì(ë¶€ë¶„) + ë‚ ì§œ + ë‚´ìš©(ë¶€ë¶„)
                        author_match = li_author.startswith(author_prefix)
                        date_match = li_date_clean == date_clean
                        
                        # ë‚´ìš© ë§¤ì¹­ (ìˆìœ¼ë©´)
                        content_match = True
                        if content and len(content) > 10:
                            try:
                                li_content = li.find_element(By.CLASS_NAME, "pui__vn15t2").text.strip()
                                content_match = content[:50] in li_content[:100]
                            except:
                                content_match = True  # ë‚´ìš© ì—†ìœ¼ë©´ íŒ¨ìŠ¤
                        
                        if author_match and date_match and content_match:
                            print(f"âœ… Found review (fallback): author='{li_author}' (starts with '{author_prefix}'), date='{li_date_clean}'")
                            target_review = li
                            break
                            
                    except:
                        continue
            
            if not target_review:
                # ì—ëŸ¬ ë©”ì‹œì§€ (date_clean, author_prefixëŠ” ì´ë¯¸ ì •ì˜ë¨)
                print(f"âŒ Could not find review!")
                print(f"   Looking for: author starts with '{author_prefix}', date='{date_clean}'")
                print(f"   Original: author='{author}', date='{date}'")
                print(f"âš ï¸ Debugging - first 5 reviews on page:")
                
                # ë””ë²„ê¹…: í˜ì´ì§€ì˜ ëª¨ë“  ë¦¬ë·° ì¶œë ¥
                for idx, li in enumerate(all_lis[:5]):
                    try:
                        debug_author = li.find_element(By.CLASS_NAME, "pui__JiVbY3").text.strip()
                        debug_date = ""
                        d_elems = li.find_elements(By.CLASS_NAME, "pui__m7nkds")
                        for d in d_elems:
                            if re.search(r'20\d{2}\.', d.text):
                                debug_date = d.text.strip()
                                break
                        debug_date_clean = re.sub(r'\([ì›”í™”ìˆ˜ëª©ê¸ˆí† ì¼]\)', '', debug_date).strip()
                        print(f"  [{idx}] Author: '{debug_author}', Date: '{debug_date}' (clean: '{debug_date_clean}')")
                    except:
                        pass
                
                raise Exception(f"Could not find review: author='{author_prefix}...', date='{date_clean}'")
            
            # Scroll to review
            print("ğŸ“œ Scrolling to review...")
            driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", target_review)
            time.sleep(1)
            
            # ğŸ›¡ï¸ ë‹µê¸€ì´ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
            print("ğŸ” Checking if reply already exists...")
            try:
                existing_reply = target_review.find_element(By.CLASS_NAME, "pui__GbW8H7")
                if existing_reply:
                    print("âš ï¸ Reply already exists!")
                    raise Exception("ì´ë¯¸ ë‹µê¸€ì´ ì¡´ì¬í•˜ëŠ” ë¦¬ë·°ì…ë‹ˆë‹¤. ë‹µê¸€ì„ ìˆ˜ì •í•˜ë ¤ë©´ ë„¤ì´ë²„ì—ì„œ ì§ì ‘ ìˆ˜ì •í•´ì£¼ì„¸ìš”.")
            except Exception as e:
                if "ì´ë¯¸ ë‹µê¸€ì´ ì¡´ì¬" in str(e):
                    raise
                # ë‹µê¸€ì´ ì—†ìœ¼ë©´ ì •ìƒ (NoSuchElementException)
                print("âœ… No existing reply, safe to proceed")
            
            # ğŸš€ CRITICAL: "ë‹µê¸€ ì“°ê¸°" ë²„íŠ¼ ì°¾ê¸° ë° í´ë¦­
            print("ğŸ–±ï¸  Finding 'ë‹µê¸€' button...")
            reply_btn = None
            
            # ì—¬ëŸ¬ ê°€ì§€ ë°©ë²•ìœ¼ë¡œ ì‹œë„ (ì•ˆì •ì„± í–¥ìƒ)
            try:
                # ë°©ë²• 1: "ë‹µê¸€" í…ìŠ¤íŠ¸ í¬í•¨
                reply_btn = target_review.find_element(By.XPATH, ".//button[contains(., 'ë‹µê¸€')]")
                print("âœ… Found by 'ë‹µê¸€' text")
            except:
                try:
                    # ë°©ë²• 2: "ë‹µê¸€ ì“°ê¸°" ì „ì²´ í…ìŠ¤íŠ¸
                    reply_btn = target_review.find_element(By.XPATH, ".//button[contains(., 'ë‹µê¸€ ì“°ê¸°')]")
                    print("âœ… Found by 'ë‹µê¸€ ì“°ê¸°' text")
                except:
                    try:
                        # ë°©ë²• 3: "ë‹µê¸€ë‹¬ê¸°" (ë„ì–´ì“°ê¸° ì—†ëŠ” ê²½ìš°)
                        reply_btn = target_review.find_element(By.XPATH, ".//button[contains(., 'ë‹µê¸€ë‹¬ê¸°')]")
                        print("âœ… Found by 'ë‹µê¸€ë‹¬ê¸°' text")
                    except:
                        print("âŒ Could not find reply button")
                        raise Exception("ë‹µê¸€ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ë¯¸ ë‹µê¸€ì´ ìˆê±°ë‚˜ í˜ì´ì§€ ë¡œë”©ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # ë²„íŠ¼ í´ë¦­
            print("ğŸ–±ï¸  Clicking reply button...")
            driver.execute_script("arguments[0].click();", reply_btn)
            time.sleep(2)
            print("âœ… Reply form opened")
            
            # Fill textarea (ì‹¤ì œ í‚¤ ì…ë ¥ìœ¼ë¡œ React ì´ë²¤íŠ¸ íŠ¸ë¦¬ê±°)
            print("âŒ¨ï¸  Waiting for textarea...")
            textarea = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.TAG_NAME, "textarea"))
            )
            
            # ğŸ›¡ï¸ BMP ë¬¸ì í•„í„°ë§ (ì´ëª¨ì§€ ë° íŠ¹ìˆ˜ ë¬¸ì ì œê±°)
            def remove_non_bmp(text):
                """
                ChromeDriverê°€ ì§€ì›í•˜ì§€ ì•ŠëŠ” BMP ë°–ì˜ ë¬¸ì ì œê±°
                (ì´ëª¨ì§€, íŠ¹ìˆ˜ ìœ ë‹ˆì½”ë“œ ë“±)
                """
                # BMP ë²”ìœ„: U+0000 ~ U+FFFF
                return ''.join(c for c in text if ord(c) <= 0xFFFF)
            
            # ì›ë³¸ í…ìŠ¤íŠ¸ ë³´ê´€ (ë¡œê¹…ìš©)
            original_reply_text = reply_text
            
            # ğŸ”¥ BMP í•„í„°ë§ (ì—ëŸ¬ ë°©ì§€)
            reply_text_safe = remove_non_bmp(reply_text)
            
            # í•„í„°ë§ ê²°ê³¼ ë¡œê¹…
            if len(reply_text_safe) < len(original_reply_text):
                removed_chars = len(original_reply_text) - len(reply_text_safe)
                print(f"âš ï¸  Removed {removed_chars} non-BMP characters (emojis/special chars)")
            
            print(f"âŒ¨ï¸  Filling reply with send_keys: {reply_text_safe[:30]}...")
            
            # ğŸš€ STRATEGY: textareaì— focusë¥¼ ì£¼ê³  í´ë¦­í•œ ë‹¤ìŒ ì…ë ¥
            driver.execute_script("arguments[0].focus();", textarea)
            driver.execute_script("arguments[0].click();", textarea)
            time.sleep(0.3)
            
            textarea.clear()
            time.sleep(0.5)
            
            # ğŸš€ CRITICAL: send_keys()ë¡œ ì‹¤ì œ í‚¤ ì…ë ¥ (React ì´ë²¤íŠ¸ íŠ¸ë¦¬ê±°)
            # í•„í„°ë§ëœ í…ìŠ¤íŠ¸ ì‚¬ìš© (BMPë§Œ)
            textarea.send_keys(reply_text_safe)
            time.sleep(1)
            
            # ğŸ” ê²€ì¦: í…ìŠ¤íŠ¸ê°€ ì‹¤ì œë¡œ ì…ë ¥ë˜ì—ˆëŠ”ì§€ í™•ì¸
            actual_value = driver.execute_script("return arguments[0].value;", textarea)
            if len(actual_value) < 10:
                print(f"âš ï¸  send_keys failed (value: {len(actual_value)} chars)")
                print("   ğŸ”§ Retrying with enhanced JavaScript...")
                
                # ğŸš€ ë” ê°•ë ¥í•œ JavaScript ì…ë ¥ (React ì´ë²¤íŠ¸ í™•ì‹¤í•˜ê²Œ íŠ¸ë¦¬ê±°)
                driver.execute_script("""
                    const textarea = arguments[0];
                    const text = arguments[1];
                    
                    // ê°’ ì„¤ì •
                    textarea.value = text;
                    
                    // Reactê°€ ê°ì§€í•  ìˆ˜ ìˆë„ë¡ ë‹¤ì–‘í•œ ì´ë²¤íŠ¸ íŠ¸ë¦¬ê±°
                    textarea.dispatchEvent(new Event('focus', { bubbles: true }));
                    textarea.dispatchEvent(new Event('input', { bubbles: true }));
                    textarea.dispatchEvent(new Event('change', { bubbles: true }));
                    textarea.dispatchEvent(new Event('blur', { bubbles: true }));
                    
                    // React 16+ ëŒ€ì‘: nativeEvent descriptor ì„¤ì •
                    const inputEvent = new InputEvent('input', {
                        data: text,
                        inputType: 'insertText',
                        bubbles: true,
                        cancelable: true
                    });
                    textarea.dispatchEvent(inputEvent);
                """, textarea, reply_text_safe)
                
                time.sleep(1)  # React ìƒíƒœ ì—…ë°ì´íŠ¸ ëŒ€ê¸°
                actual_value = driver.execute_script("return arguments[0].value;", textarea)
                print(f"   âœ… After enhanced JS: {len(actual_value)} chars")
                
                if len(actual_value) < 10:
                    raise Exception(f"Failed to fill textarea (value: {len(actual_value)} chars)")
            else:
                print(f"âœ… Text input verified: {len(actual_value)} chars")
            
            # ğŸš€ target_review ë‚´ì—ì„œë§Œ "ë“±ë¡" ì°¾ê¸°
            print("ğŸ“¤ Finding 'ë“±ë¡' button in target review...")
            try:
                submit_btn = target_review.find_element(By.XPATH, ".//button[contains(text(), 'ë“±ë¡')]")
                print("âœ… Found 'ë“±ë¡' in target review")
            except:
                print("âš ï¸ Not in target, searching all visible buttons...")
                all_btns = driver.find_elements(By.XPATH, "//button[contains(., 'ë“±ë¡')]")
                visible = [b for b in all_btns if b.is_displayed()]
                submit_btn = visible[-1] if visible else None
                if not submit_btn:
                    raise Exception("No 'ë“±ë¡' button found")
                print(f"âœ… Found visible 'ë“±ë¡' (index {len(visible)-1})")
            
            # ğŸ” ë“±ë¡ ì „ ìµœì¢… ê²€ì¦: textarea ê°’ ì¬í™•ì¸
            final_value = driver.execute_script("return arguments[0].value;", textarea)
            print(f"ğŸ” Final textarea check before submit: {len(final_value)} chars")
            if len(final_value) < 10:
                raise Exception(f"Textarea empty before submit! (value: {len(final_value)} chars)")
            
            # ğŸ” ë“±ë¡ ë²„íŠ¼ ìƒíƒœ í™•ì¸
            is_disabled = submit_btn.get_attribute("disabled")
            is_aria_disabled = submit_btn.get_attribute("aria-disabled")
            if is_disabled or is_aria_disabled == "true":
                print(f"âŒ Submit button is disabled! (disabled={is_disabled}, aria-disabled={is_aria_disabled})")
                raise Exception("ë“±ë¡ ë²„íŠ¼ì´ ë¹„í™œì„±í™” ìƒíƒœì…ë‹ˆë‹¤")
            
            print("ğŸ–±ï¸  Clicking 'ë“±ë¡'...")
            driver.execute_script("arguments[0].click();", submit_btn)
            time.sleep(2)
            
            # ğŸ” ë“±ë¡ í›„ ì—ëŸ¬ ë©”ì‹œì§€ í™•ì¸
            try:
                # ğŸ”§ ë„¤ì´ë²„ ì—ëŸ¬ ë©”ì‹œì§€ë§Œ ì •í™•íˆ ê°ì§€ (false positive ë°©ì§€)
                error_selectors = [
                    "[role='alert']",
                    ".alert-error",
                    ".error-message",
                    "[class*='toast'][class*='error']",
                    "[class*='notification'][class*='error']"
                ]
                error_found = False
                for selector in error_selectors:
                    error_elems = driver.find_elements(By.CSS_SELECTOR, selector)
                    for elem in error_elems:
                        if elem.is_displayed():
                            text = elem.text.strip()
                            # ğŸ”§ í˜ì´ì§€ íƒ€ì´í‹€/í—¤ë”ëŠ” ì œì™¸ (false positive ë°©ì§€)
                            if text and len(text) > 5 and "ìŠ¤ë§ˆíŠ¸í”Œë ˆì´ìŠ¤" not in text and "SmartPlace" not in text:
                                print(f"âš ï¸  Error message detected: {text[:100]}")
                                error_found = True
                if not error_found:
                    print("   âœ… No error messages detected")
            except:
                pass
            
            time.sleep(3)  # ì´ 5ì´ˆ ëŒ€ê¸° (2ì´ˆ + 3ì´ˆ)
            
            # ğŸš€ CRITICAL: ê²€ì¦ - ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë°œìƒ
            print("ğŸ” Verifying reply...")
            time.sleep(4)  # 4ì´ˆ ëŒ€ê¸° (ë„¤ì´ë²„ ë Œë”ë§ + DOM ì—…ë°ì´íŠ¸)
            
            reply_verified = False
            
            # ğŸ”§ FIX: ì—¬ëŸ¬ ë²ˆ ì¬ì‹œë„ (ë„¤ì´ë²„ ë Œë”ë§ì´ ëŠë¦´ ìˆ˜ ìˆìŒ)
            max_retry = 3
            for retry in range(max_retry):
                try:
                    if retry > 0:
                        print(f"   ğŸ”„ Verification retry {retry}/{max_retry-1}...")
                        time.sleep(2)  # ì¬ì‹œë„ ì‹œ ì¶”ê°€ ëŒ€ê¸°
                    
                    # ì‘ì„±ì+ë‚ ì§œë¡œ ë‹¤ì‹œ ì°¾ê¸° (ì´ë¯¸ ìœ„ì—ì„œ ì •ì˜ëœ ë³€ìˆ˜ ì‚¬ìš©)
                    
                    all_lis = driver.find_elements(By.TAG_NAME, "li")
                    for li in all_lis:
                        try:
                            li_author = li.find_element(By.CLASS_NAME, "pui__JiVbY3").text.strip()
                            if not li_author.startswith(author_prefix):
                                continue
                            
                            li_date = ""
                            d_elems = li.find_elements(By.CLASS_NAME, "pui__m7nkds")
                            for d in d_elems:
                                if re.search(r'20\d{2}\.', d.text):
                                    li_date = d.text.strip()
                                    break
                            
                            li_date_clean = re.sub(r'\([^)]*\)', '', li_date).strip()
                            
                            if li_date_clean == date_clean:
                                # ì´ ë¦¬ë·°ì—ì„œ ë‹µê¸€ ìš”ì†Œ ì°¾ê¸°
                                reply_elem = li.find_element(By.CLASS_NAME, "pui__GbW8H7")
                                reply_preview = reply_elem.text[:50]
                                print(f"âœ… Reply verified: {reply_preview}...")
                                reply_verified = True
                                break
                        except:
                            continue
                    
                    if reply_verified:
                        break  # ì„±ê³µí•˜ë©´ ì¬ì‹œë„ ì¤‘ë‹¨
                        
                except Exception as e:
                    if retry == max_retry - 1:
                        print(f"âŒ Verification error: {e}")
            
            # ğŸš¨ CRITICAL: Verification ì‹¤íŒ¨ = ë‹µê¸€ ë“±ë¡ ì‹¤íŒ¨
            if not reply_verified:
                # ë””ë²„ê¹…: í˜ì´ì§€ ìƒíƒœ í™•ì¸
                print("ğŸ” Debug: Checking page state...")
                try:
                    current_url = driver.current_url
                    print(f"   Current URL: {current_url}")
                    # ì—ëŸ¬ ë©”ì‹œì§€ê°€ ìˆëŠ”ì§€ ë‹¤ì‹œ í™•ì¸
                    error_elems = driver.find_elements(By.CSS_SELECTOR, "[class*='error'], [class*='alert'], [role='alert']")
                    if error_elems:
                        for elem in error_elems:
                            if elem.is_displayed():
                                print(f"   âš ï¸ Error on page: {elem.text[:100]}")
                except:
                    pass
                raise Exception("Reply verification failed - ë‹µê¸€ì´ ì‹¤ì œë¡œ ê²Œì‹œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
            if reply_verified:
                print(f"âœ… Reply posted and verified successfully!")
                return {
                    'success': True,
                    'message': 'Reply posted and verified successfully'
                }
            else:
                print(f"âš ï¸ Reply posted (verification skipped due to DOM changes)")
                return {
                    'success': True,
                    'message': 'Reply posted successfully (verification skipped)',
                    'verified': False
                }
            
        except Exception as e:
            error_msg = str(e)
            print(f"âŒ Error posting reply: {error_msg}")
            logger.error(f"Error posting reply: {error_msg}")
            raise HTTPException(status_code=500, detail=f"Error posting reply: {error_msg}")
        
        finally:
            # ğŸš€ PERSISTENT BROWSER: persistent browserëŠ” ë‹«ì§€ ì•ŠìŒ!
            if driver and not driver_is_persistent:
                try:
                    print("ğŸ”„ Closing temporary browser...")
                    driver.quit()
                    print("âœ… Temporary browser closed")
                except Exception as e:
                    print(f"âš ï¸ Error closing driver: {e}")
            elif driver and driver_is_persistent:
                print("â™»ï¸ Keeping persistent browser alive")
    
    def post_reply(self, place_id: str, review_id: str, reply_text: str) -> Dict:
        """Post a reply to a review in Smartplace Center"""
        driver = None
        driver_is_persistent = False
        current_user_id = self.active_user_id
        
        try:
            print(f"ğŸ’¬ Posting reply to review: {review_id} for user: {current_user_id}")
            logger.info(f"ğŸ’¬ Posting reply to review: {review_id}")
            
            # ğŸš€ PERSISTENT BROWSER: ë¨¼ì € ê¸°ì¡´ ë¸Œë¼ìš°ì € í™•ì¸
            from services.persistent_browser_manager import browser_manager
            
            driver = browser_manager.get_browser(current_user_id)
            
            if driver:
                print(f"â™»ï¸ Reusing persistent browser for {current_user_id}")
                driver_is_persistent = True
            else:
                print(f"ğŸ†• Creating new browser for {current_user_id} (no persistent browser)")
                driver = self._create_driver(headless=True, user_id=current_user_id)
                driver_is_persistent = False
            
            # Go to Smartplace reviews page (NOT mobile version)
            reviews_url = f'https://new.smartplace.naver.com/bizes/place/{place_id}/reviews?menu=visitor'
            print(f"ğŸ”— Opening: {reviews_url}")
            driver.get(reviews_url)
            time.sleep(2)
            
            # Handle popup
            try:
                popup_btn = driver.find_element(By.CSS_SELECTOR, "button.Modal_btn_confirm__uQZFR")
                if popup_btn.is_displayed():
                    driver.execute_script("arguments[0].click();", popup_btn)
                    time.sleep(1)
            except:
                pass
            
            # Find all review cards
            print("ğŸ” Finding target review...")
            all_lis = driver.find_elements(By.TAG_NAME, "li")
            
            target_review = None
            target_author = None
            
            # Extract author and date from review_id for more flexible matching
            # Try multiple matching strategies
            
            for li in all_lis:
                try:
                    # Get review data
                    author = li.find_element(By.CLASS_NAME, "pui__JiVbY3").text.strip()
                    date = "ë‚ ì§œ ì—†ìŒ"
                    try:
                        d_elems = li.find_elements(By.CLASS_NAME, "pui__m7nkds")
                        for d in d_elems:
                            if re.search(r'20\d{2}\.', d.text):
                                date = d.text.strip()
                                break
                    except: pass
                    
                    content = ""
                    try:
                        content = li.find_element(By.CLASS_NAME, "pui__vn15t2").text.strip()[:30]
                    except: pass
                    
                    # Generate ID to match (exact match)
                    unique_str = f"{author}-{date}-{content}"
                    rid = hashlib.md5(unique_str.encode()).hexdigest()[:8]
                    generated_id = f"naver-{place_id}-{rid}"
                    
                    if generated_id == review_id:
                        print(f"âœ… Found target review (exact match): {author}")
                        target_review = li
                        target_author = author
                        break
                    
                    # Fallback: Try with empty content (in case content parsing differs)
                    fallback_str = f"{author}-{date}-"
                    fallback_rid = hashlib.md5(fallback_str.encode()).hexdigest()[:8]
                    fallback_id = f"naver-{place_id}-{fallback_rid}"
                    
                    if fallback_id == review_id:
                        print(f"âœ… Found target review (fallback match): {author}")
                        target_review = li
                        target_author = author
                        break
                        
                except:
                    continue
            
            if not target_review:
                raise Exception(f"Could not find review with ID: {review_id}")
            
            # Scroll to review
            driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", target_review)
            time.sleep(0.5)
            
            # Click reply button: "ë‹µê¸€ ì“°ê¸°"
            print("ğŸ–±ï¸  Clicking 'ë‹µê¸€ ì“°ê¸°' button...")
            reply_btn = target_review.find_element(By.XPATH, ".//button[contains(., 'ë‹µê¸€')]")
            driver.execute_script("arguments[0].click();", reply_btn)
            time.sleep(1)
            
            # Find textarea (should appear after clicking)
            print("âŒ¨ï¸  Filling reply text...")
            textarea = target_review.find_element(By.TAG_NAME, "textarea")
            textarea.clear()
            textarea.send_keys(reply_text)
            time.sleep(0.5)
            
            # Click submit button: "ë“±ë¡"
            print("ğŸ“¤ Clicking 'ë“±ë¡' button...")
            submit_btn = target_review.find_element(By.XPATH, ".//button[contains(., 'ë“±ë¡')]")
            driver.execute_script("arguments[0].click();", submit_btn)
            time.sleep(2)
            
            # Check for success (reply should now appear)
            try:
                reply_elem = target_review.find_element(By.CLASS_NAME, "pui__GbW8H7")
                print(f"âœ… Reply posted successfully! Reply text: {reply_elem.text[:50]}...")
            except:
                print("âš ï¸ Could not verify reply immediately (might need refresh)")
            
            # ğŸš€ UPDATE cache instead of clearing it (better UX)
            # Find the review in cache and update has_reply
            # Note: We need to update ALL cache entries for this place_id
            cache_keys_to_update = [k for k in self._reviews_cache.keys() if k.startswith(f"{place_id}:")]
            
            updated = False
            for cache_key in cache_keys_to_update:
                if cache_key in self._reviews_cache:
                    for review in self._reviews_cache[cache_key]['data']:
                        if review['review_id'] == review_id:
                            review['has_reply'] = True
                            review['reply'] = reply_text
                            review['reply_date'] = datetime.now().strftime('%Y. %m. %d')
                            print(f"âœ… Updated review {review_id} in cache ({cache_key})")
                            updated = True
            
            if not updated:
                print(f"âš ï¸ No cache found for place {place_id}, will refresh on next load")
            
            # Rate limiting
            time.sleep(settings.naver_rate_limit_delay)
            
            logger.info("âœ… Reply posted")
            return {
                'success': True,
                'message': 'Reply posted successfully',
                'review_id': review_id
            }
        
        except Exception as e:
            error_msg = str(e)
            print(f"âŒ Error posting reply: {error_msg}")
            logger.error(f"Error posting reply: {error_msg}")
            raise HTTPException(status_code=500, detail=f"Error posting reply: {error_msg}")
        
        finally:
            # ğŸš€ PERSISTENT BROWSER: persistent browserëŠ” ë‹«ì§€ ì•ŠìŒ!
            if driver and not driver_is_persistent:
                driver.quit()
                print("ğŸ”’ Closed temporary browser")
            elif driver and driver_is_persistent:
                print("â™»ï¸ Keeping persistent browser alive")
    
    def get_loading_progress(self, place_id: str) -> Dict:
        """Get current loading progress for a place"""
        if place_id in self._loading_progress:
            progress = self._loading_progress[place_id]
            # Clean up completed/error status after 30 seconds (longer to ensure frontend sees it)
            if progress['status'] in ['completed', 'error']:
                age = datetime.now() - progress['timestamp']
                if age > timedelta(seconds=30):
                    del self._loading_progress[place_id]
                    return {'status': 'idle', 'count': 0, 'message': ''}
            return progress
        else:
            return {'status': 'idle', 'count': 0, 'message': ''}
    
    def logout(self) -> Dict:
        """Logout and clear session"""
        try:
            current_user_id = self.active_user_id
            
            if os.path.exists(self.session_file):
                os.remove(self.session_file)
            
            # ğŸš€ PERSISTENT BROWSER: ë¸Œë¼ìš°ì € ì¢…ë£Œ
            from services.persistent_browser_manager import browser_manager
            browser_manager.remove_browser(current_user_id)
            print(f"ğŸ—‘ï¸ Persistent browser removed for {current_user_id}")
            
            # ğŸš€ Clear cache on logout (userë³„ë¡œ í´ë¦¬ì–´!)
            if current_user_id in self._places_cache:
                del self._places_cache[current_user_id]
            if current_user_id in self._places_cache_time:
                del self._places_cache_time[current_user_id]
            # Reviews cacheëŠ” place_idë³„ë¡œ ê´€ë¦¬ë˜ë¯€ë¡œ ì „ì²´ í´ë¦¬ì–´ (ì¶”í›„ ê°œì„  ê°€ëŠ¥)
            self._reviews_cache = {}  # Clear reviews cache too
            self._loading_progress = {}  # Clear progress too
            print(f"ğŸ—‘ï¸ Cache cleared for user {current_user_id}")
            
            return {
                'success': True,
                'message': 'Successfully logged out'
            }
        except Exception as e:
            return {
                'success': False,
                'message': f'Error logging out: {str(e)}'
            }


# Create singleton instance
naver_automation_selenium = NaverPlaceAutomationSelenium()
