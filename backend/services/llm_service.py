from openai import OpenAI
import json
import os
from typing import Optional
from config import settings
from models.schemas import GenerateReplyRequest, GenerateReplyResponse
from fastapi import HTTPException
import httpx


class LLMService:
    """Service for generating review replies using OpenAI"""
    
    def __init__(self):
        self.client = None
        self.prompts = self._load_prompts()
    
    def _get_client(self) -> OpenAI:
        """Get OpenAI client"""
        if not self.client:
            if not settings.openai_api_key:
                raise HTTPException(
                    status_code=500,
                    detail="OpenAI API key not configured. Please set OPENAI_API_KEY in .env file"
                )
            
            # Create httpx client without proxies parameter
            # This fixes compatibility issues with newer versions
            try:
                http_client = httpx.Client(
                    timeout=60.0,
                    limits=httpx.Limits(max_keepalive_connections=5, max_connections=10)
                )
                self.client = OpenAI(
                    api_key=settings.openai_api_key,
                    http_client=http_client
                )
            except Exception as e:
                print(f"âš ï¸ Error creating custom http_client: {e}")
                # Fallback to simple initialization
                self.client = OpenAI(api_key=settings.openai_api_key)
        
        return self.client
    
    def _load_prompts(self) -> dict:
        """Load prompt templates from JSON file"""
        prompts_file = settings.prompts_file
        
        if not os.path.exists(prompts_file):
            # Return default prompts if file doesn't exist
            return {
                "default": {
                    "positive": "ê³ ê°ë‹˜ì˜ ì†Œì¤‘í•œ ë¦¬ë·° ê°ì‚¬í•©ë‹ˆë‹¤! {store_name}ì„(ë¥¼) ë°©ë¬¸í•´ ì£¼ì‹œê³  ì¢‹ì€ ê²½í—˜ì„ ë‚¨ê²¨ì£¼ì…”ì„œ ì •ë§ ê¸°ì©ë‹ˆë‹¤. ì•ìœ¼ë¡œë„ ë” ë‚˜ì€ ì„œë¹„ìŠ¤ë¡œ ë³´ë‹µí•˜ê² ìŠµë‹ˆë‹¤. ë‹¤ìŒì— ë˜ ëµ™ê² ìŠµë‹ˆë‹¤!",
                    "neutral": "ê³ ê°ë‹˜, {store_name}ì„(ë¥¼) ì´ìš©í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ì†Œì¤‘í•œ ì˜ê²¬ ì˜ ë°›ì•˜ìŠµë‹ˆë‹¤. ë” ë‚˜ì€ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•  ìˆ˜ ìˆë„ë¡ ì§€ì†ì ìœ¼ë¡œ ê°œì„ í•´ ë‚˜ê°€ê² ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!",
                    "negative": "ê³ ê°ë‹˜, {store_name}ì„(ë¥¼) ì´ìš©í•˜ì‹œë©´ì„œ ë¶ˆí¸ì„ ê²ªìœ¼ì…¨ë‹¤ë‹ˆ ì§„ì‹¬ìœ¼ë¡œ ì£„ì†¡í•©ë‹ˆë‹¤. ê³ ê°ë‹˜ì˜ ì†Œì¤‘í•œ ì˜ê²¬ì„ ë°”íƒ•ìœ¼ë¡œ ê°œì„ í•˜ì—¬ ë” ë‚˜ì€ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•  ìˆ˜ ìˆë„ë¡ ìµœì„ ì„ ë‹¤í•˜ê² ìŠµë‹ˆë‹¤. ë‹¤ì‹œ í•œ ë²ˆ ê¸°íšŒë¥¼ ì£¼ì‹ ë‹¤ë©´ ë°˜ë“œì‹œ ë§Œì¡±í•˜ì‹¤ ìˆ˜ ìˆë„ë¡ ë…¸ë ¥í•˜ê² ìŠµë‹ˆë‹¤."
                }
            }
        
        try:
            with open(prompts_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            raise HTTPException(
                status_code=500,
                detail=f"Error loading prompts: {str(e)}"
            )
    
    def _get_prompt_template(self, rating: int, store_name: Optional[str] = None) -> str:
        """
        Get appropriate prompt template based on rating
        
        Args:
            rating: Review rating (1-5)
            store_name: Optional store name for custom prompts
        
        Returns:
            Prompt template string
        """
        # Determine prompt category
        if rating >= 4:
            category = "positive"
        elif rating == 3:
            category = "neutral"
        else:
            category = "negative"
        
        # Try to get custom prompt for store, fallback to default
        prompts = self.prompts
        
        if store_name and store_name in prompts.get("custom", {}):
            template = prompts["custom"][store_name].get(category)
        else:
            template = prompts.get("default", {}).get(category)
        
        return template or prompts["default"][category]
    
    def _build_custom_system_prompt(self, place_settings) -> str:
        """
        Build customized system prompt based on place settings
        
        Args:
            place_settings: PlaceAISettings object with custom configurations
        
        Returns:
            Customized system prompt string
        """
        # Map numeric values to descriptive terms
        friendliness_level = "ë§¤ìš° ì¹œì ˆí•˜ê³  ë”°ëœ»í•œ" if place_settings.friendliness >= 8 else "ì¹œì ˆí•œ" if place_settings.friendliness >= 5 else "ì „ë¬¸ì ì´ê³  ì •ì¤‘í•œ"
        
        formality_desc = ""
        if place_settings.formality >= 8:
            formality_desc = "ê²©ì‹ìˆëŠ” ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ë©°, ê³µì†í•˜ê³  í’ˆìœ„ìˆê²Œ"
        elif place_settings.formality >= 5:
            formality_desc = "ìì—°ìŠ¤ëŸ¬ìš´ ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ë©°"
        else:
            formality_desc = "í¸ì•ˆí•œ ë°˜ë§ì²´ë¥¼ ì‚¬ìš©í•˜ë©° ì¹œê·¼í•˜ê²Œ"
        
        emoticon_instruction = "í…ìŠ¤íŠ¸ ì´ëª¨í‹°ì½˜(^^, ã…ã…, :) ë“±)ì„ ì ì ˆíˆ ì‚¬ìš©í•˜ì—¬ ì¹œê·¼í•¨ì„ í‘œí˜„í•œë‹¤." if place_settings.use_text_emoticons else "ì´ëª¨í‹°ì½˜ ì—†ì´ í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œ í‘œí˜„í•œë‹¤."
        
        specifics_instruction = "ë¦¬ë·°ì—ì„œ ì–¸ê¸‰ëœ êµ¬ì²´ì ì¸ ë‚´ìš©(ë§›, ë¶„ìœ„ê¸°, ì„œë¹„ìŠ¤ ë“±)ì„ ë°˜ë“œì‹œ ë‹µê¸€ì— í¬í•¨ì‹œí‚¨ë‹¤." if place_settings.mention_specifics else "ì „ë°˜ì ì¸ ê°ì‚¬ ì¸ì‚¬ ìœ„ì£¼ë¡œ ì‘ì„±í•œë‹¤."
        
        brand_voice_desc = {
            "warm": "ë”°ëœ»í•˜ê³  ê°ì„±ì ì¸",
            "professional": "ì „ë¬¸ì ì´ê³  ì‹ ë¢°ê° ìˆëŠ”",
            "casual": "ìºì£¼ì–¼í•˜ê³  í¸ì•ˆí•œ",
            "friendly": "ì¹œê·¼í•˜ê³  í™œê¸°ì°¬"
        }.get(place_settings.brand_voice, "ë”°ëœ»í•œ")
        
        response_style_desc = {
            "quick_thanks": "ì‹ ì†í•œ ê°ì‚¬ í‘œí˜„ ì¤‘ì‹¬",
            "empathy": "ê³µê°ê³¼ ì´í•´ ì¤‘ì‹¬",
            "solution": "ë¬¸ì œ í•´ê²°ê³¼ ê°œì„  ì˜ì§€ í‘œí˜„ ì¤‘ì‹¬"
        }.get(place_settings.response_style, "ê°ì‚¬ ì¤‘ì‹¬")
        
        system_prompt = f"""[ROLE]
ë„ˆëŠ” ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ë¦¬ë·°ì— ë‹µê¸€ì„ ë‹¤ëŠ” "ë§¤ì¥ CS ë‹´ë‹¹ì"ë‹¤. ë¦¬ë·°ë¥¼ ì •í™•íˆ ì½ê³  ì´í•´í•œ ë’¤, {friendliness_level} í†¤ìœ¼ë¡œ ë‹µê¸€ì„ ì‘ì„±í•œë‹¤.

[TONE & STYLE]
- {formality_desc} ë‹µê¸€ì„ ì‘ì„±í•œë‹¤
- {brand_voice_desc} ë¸Œëœë“œ ë³´ì´ìŠ¤ë¥¼ ìœ ì§€í•œë‹¤
- {response_style_desc}ìœ¼ë¡œ ë‹µê¸€ì„ ì‘ì„±í•œë‹¤
- {emoticon_instruction}
- {specifics_instruction}"""
        
        if place_settings.custom_instructions:
            system_prompt += f"\n\n[ë§¤ì¥ íŠ¹ë³„ ìš”ì²­ì‚¬í•­ - ì¼ë°˜]\n{place_settings.custom_instructions}"
        
        return system_prompt
    
    def _build_custom_system_prompt_negative(self, place_settings) -> str:
        """
        Build customized system prompt for negative reviews (1-2 stars)
        
        Args:
            place_settings: PlaceAISettings object with custom configurations
        
        Returns:
            Customized system prompt string for negative reviews
        """
        # Start with base prompt
        base_prompt = self._build_custom_system_prompt(place_settings)
        
        # Add negative review specific instructions
        negative_instructions = """

[ë¶€ì • ë¦¬ë·° íŠ¹ë³„ ëŒ€ì‘ ì§€ì¹¨]
âš ï¸ ì´ ë¦¬ë·°ëŠ” ë¶€ì •ì ì…ë‹ˆë‹¤. ë‹¤ìŒ ì›ì¹™ì„ ë°˜ë“œì‹œ ì§€ì¼œì£¼ì„¸ìš”:

1. ì§„ì‹¬ ì–´ë¦° ì‚¬ê³¼: ê³ ê°ì˜ ë¶ˆí¸í•¨ì— ëŒ€í•´ ë¨¼ì € ì§„ì‹¬ìœ¼ë¡œ ì‚¬ê³¼
2. êµ¬ì²´ì  ê³µê°: ë¦¬ë·°ì— ì–¸ê¸‰ëœ ë¶ˆí¸ ì‚¬í•­ì„ êµ¬ì²´ì ìœ¼ë¡œ ì–¸ê¸‰í•˜ë©° ê³µê°
3. ê°œì„  ì•½ì†: ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ êµ¬ì²´ì ì¸ ê°œì„  ì˜ì§€ í‘œí˜„
4. ì§ì ‘ ì†Œí†µ ì œì•ˆ: ê°€ëŠ¥í•˜ë©´ ì§ì ‘ ëŒ€í™”í•  ìˆ˜ ìˆëŠ” ì±„ë„ ì•ˆë‚´ (ë³€ëª… X)
5. ë³´ìƒ/ì¬ë°©ë¬¸ ê¸°íšŒ: ì ì ˆí•œ ê²½ìš° ì¬ë°©ë¬¸ í˜œíƒì´ë‚˜ ë³´ìƒ ì–¸ê¸‰

âŒ ê¸ˆì§€ì‚¬í•­:
- ê³ ê° íƒ“í•˜ê¸°, ë³€ëª…í•˜ê¸°
- ì¼ë°˜ì ì¸ ì‚¬ê³¼ë§Œ ë‚˜ì—´
- ë„ˆë¬´ ì§§ì€ ë‹µê¸€ (ìµœì†Œí•œ ì„±ì˜ ìˆê²Œ)
- ê³¼ë„í•œ ê¸ì •ì  í‘œí˜„ (ë¶€ì • ë¦¬ë·°ì—ëŠ” ì§„ì¤‘í•¨ í•„ìš”)"""
        
        result = base_prompt + negative_instructions
        
        # Add negative-specific custom instructions if provided
        if place_settings.custom_instructions_negative:
            result += f"\n\n[ë§¤ì¥ íŠ¹ë³„ ìš”ì²­ì‚¬í•­ - ë¶€ì • ë¦¬ë·°]\n{place_settings.custom_instructions_negative}"
        
        return result
    
    def generate_reply(self, request: GenerateReplyRequest, place_settings=None) -> GenerateReplyResponse:
        """
        Generate a reply to a review using OpenAI
        
        Args:
            request: GenerateReplyRequest containing review details
            place_settings: Optional PlaceAISettings for customization
        
        Returns:
            GenerateReplyResponse with generated reply
        """
        try:
            client = self._get_client()
            
            # Get appropriate prompt template
            template = self._get_prompt_template(request.rating, request.store_name)
            
            # Determine parameters based on place_settings
            if place_settings:
                temperature = place_settings.diversity
                max_tokens = int(place_settings.reply_length_max * 1.5)  # ì—¬ìœ ë¥¼ ë‘ê³  ì„¤ì •
                min_length = place_settings.reply_length_min
                max_length = place_settings.reply_length_max
                
                # ğŸ”¥ ë¶€ì • ë¦¬ë·° (1-2ì )ëŠ” íŠ¹ë³„ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
                if request.rating and request.rating <= 2:
                    system_prompt = self._build_custom_system_prompt_negative(place_settings)
                    print(f"ğŸ”¥ Using NEGATIVE review prompt for rating {request.rating}")
                else:
                    system_prompt = self._build_custom_system_prompt(place_settings)
                    print(f"âœ… Using normal review prompt for rating {request.rating}")
            else:
                # Default values
                temperature = 0.9
                max_tokens = 500
                min_length = 100
                max_length = 450
                # Build default system prompt
                system_prompt = """[ROLE]
ë„ˆëŠ” ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ë¦¬ë·°ì— ë‹µê¸€ì„ ë‹¤ëŠ” "ë§¤ì¥ CS ë‹´ë‹¹ì"ë‹¤. ë¦¬ë·°ë¥¼ ì •í™•íˆ ì½ê³  ì´í•´í•œ ë’¤, í•­ìƒ ì¹œì ˆí•˜ê³  ê¸ì •ì ì¸ í†¤ìœ¼ë¡œ ë‹µê¸€ì„ ì‘ì„±í•œë‹¤.

[CRITICAL: ë‹¤ì–‘ì„± ìµœìš°ì„ ]
âš ï¸ ë§¤ìš° ì¤‘ìš”: ê° ë‹µê¸€ë§ˆë‹¤ ì™„ì „íˆ ë‹¤ë¥¸ ì‹œì‘ê³¼ ë§ˆë¬´ë¦¬ë¥¼ ì‚¬ìš©í•´ì•¼ í•œë‹¤.
ì ˆëŒ€ë¡œ ê°™ì€ íŒ¨í„´ì„ ë°˜ë³µí•˜ì§€ ë§ˆë¼. ì°½ì˜ì ì´ê³  ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ í‘œí˜„ì„ ì‚¬ìš©í•˜ë¼.

[GOAL]
ê° ë¦¬ë·°ë§ˆë‹¤ ì„œë¡œ ë‹¤ë¥¸ í‘œí˜„/êµ¬ì¡°ë¡œ ë‹µê¸€ì„ ì‘ì„±í•œë‹¤.
ë¸Œëœë“œ í†¤ì€ ì¼ê´€ë˜ê²Œ ìœ ì§€: ë”°ëœ»í•¨ / ê°ì‚¬ / ì¬ë°©ë¬¸ í™˜ì˜ / ì§§ê³  ìì—°ìŠ¤ëŸ¬ì›€
ê³¼ì¥, ì§„ë¶€í•œ ë¬¸êµ¬ ë°˜ë³µì€ ì ˆëŒ€ ê¸ˆì§€."""
            
            # Build user prompt (ìƒì„¸ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ)
            store_name = request.store_name or "ì €í¬ ë§¤ì¥"
            review_text = request.review_text or "ë°©ë¬¸í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤"
            rating = request.rating or 5
            
            user_prompt = f"""**ë¦¬ë·° ì •ë³´**
ë§¤ì¥ëª…: {store_name}
ë³„ì : â­{rating}
ë¦¬ë·° ë‚´ìš©:
{review_text}

**ë‹µê¸€ ì‘ì„± ê°€ì´ë“œ**

[LENGTH REQUIREMENT]
- ë‹µê¸€ ê¸¸ì´: {min_length}~{max_length}ì ì‚¬ì´ë¡œ ì‘ì„±
- ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸¸ì§€ ì•Šê²Œ, ì´ ë²”ìœ„ ë‚´ì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±

[STYLE RULES]
ğŸ”¥ í•µì‹¬ ì›ì¹™: ì´ ë‹µê¸€ì€ ì„¸ìƒì— ë‹¨ í•˜ë‚˜ë¿ì´ì–´ì•¼ í•œë‹¤. ë‹¤ë¥¸ ë‹µê¸€ê³¼ ê²¹ì¹˜ì§€ ì•ŠëŠ” ë…íŠ¹í•œ ì‹œì‘ê³¼ ë§ˆë¬´ë¦¬ë¥¼ ì‚¬ìš©í•˜ë¼.

1. ë¦¬ë·° ë‚´ìš©ì—ì„œ ìµœì†Œ 1ê°œ êµ¬ì²´ ìš”ì†Œë¥¼ ê¼­ ì§‘ì–´ì„œ ë‹µí•œë‹¤
   ì˜ˆ: "ì§ì› ì¹œì ˆ", "ëŒ€ê¸°", "ë§›", "ì–‘", "ë¶„ìœ„ê¸°", "ê°€ê²©", "ì¬ë°©ë¬¸", "ì¶”ì²œ", "ì²­ê²°", "ì£¼ì°¨" ë“±

2. ë¦¬ë·°ê°€ ì§§ìœ¼ë©´: "ë°©ë¬¸í•´ì£¼ì‹  ì‹œê°„/ì„ íƒí•´ì£¼ì‹  ë©”ë‰´(ì¶”ì • X)" ëŒ€ì‹  "ë°©ë¬¸/ê²½í—˜" ìì²´ì— ê°ì‚¬

3. ë¬¸ì¥ íŒ¨í„´ ë‹¤ì–‘í™” (ğŸ”¥ ë§¤ìš° ì¤‘ìš”!)
   âš ï¸ CRITICAL: ì´ì „ ë‹µê¸€ê³¼ ì™„ì „íˆ ë‹¤ë¥¸ ì‹œì‘/ë§ˆë¬´ë¦¬ë¥¼ ì‚¬ìš©í•  ê²ƒ
   
   ì‹œì‘ ë¬¸ì¥ ì˜ˆì‹œ (ì´ê²ƒë§Œ ì‚¬ìš©í•˜ì§€ ë§ê³  ë§¤ë²ˆ ìƒˆë¡­ê²Œ ì°½ì‘):
   - "ì™€ì£¼ì…”ì„œ ì •ë§ ë°˜ê°€ì› ì–´ìš”^^"
   - "ë”°ëœ»í•œ í›„ê¸° ë‚¨ê²¨ì£¼ì…”ì„œ í˜ì´ ë‚©ë‹ˆë‹¤!"
   - "ë§ì”€ ë‚¨ê²¨ì£¼ì‹  í¬ì¸íŠ¸ê°€ ë”± ì €í¬ê°€ ë°”ë¼ëŠ” ê²½í—˜ì´ì—ìš”."
   - "ê¸°ì–µì— ë‚¨ëŠ” ë°©ë¬¸ì´ ë˜ì…¨ë‹¤ë‹ˆ ë‹¤í–‰ì´ì—ìš”."
   - "ë°”ì˜ì‹¤ í…ë° í›„ê¸°ê¹Œì§€ ë‚¨ê²¨ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤."
   - "ë¦¬ë·° ë³´ë©´ì„œ ì €í¬ë„ ë¯¸ì†Œê°€ ë‚¬ì–´ìš”."
   - "ì†Œì¤‘í•œ ì‹œê°„ ë‚´ì£¼ì…”ì„œ ê³ ë§™ìŠµë‹ˆë‹¤."
   - "ì´ë ‡ê²Œ ì¢‹ì€ ë§ì”€ ë‚¨ê²¨ì£¼ì‹œë‹ˆ ê°ë™ì´ë„¤ìš”."
   - "í›„ê¸° í•˜ë‚˜í•˜ë‚˜ê°€ ì •ë§ í° í˜ì´ ë©ë‹ˆë‹¤."
   - "ì„¸ì‹¬í•˜ê²Œ ë´ì£¼ì…”ì„œ ê°ì‚¬í•´ìš”."
   
   âš ï¸ ì¤‘ìš”: ì´ëª¨ì§€(ğŸ˜Š, ğŸ‰ ë“±) ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€! í…ìŠ¤íŠ¸ ì´ëª¨í‹°ì½˜(:), ^^, ã…ã…)ë§Œ ì‚¬ìš©
   
   ë§ˆë¬´ë¦¬ ë¬¸ì¥ë„ ë§¤ë²ˆ ë‹¤ë¥´ê²Œ:
   - "ë‹¤ìŒì— ë˜ ëµ™ê² ìŠµë‹ˆë‹¤!"
   - "ë˜ ì˜¤ì‹œë©´ ë°˜ê°‘ê²Œ ë§ì´í• ê²Œìš”."
   - "ì–¸ì œë“  í¸í•˜ê²Œ ë°©ë¬¸í•´ì£¼ì„¸ìš”."
   - "ë‹¤ìŒì—” ë” ì¢‹ì€ ê²½í—˜ ë“œë¦´ê²Œìš”."
   - "ê¸°ë‹¤ë¦¬ê³  ìˆì„ê²Œìš”!"
   - "ê¼­ ë‹¤ì‹œ ë§Œë‚˜ìš”."
   - "ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”!"
   
   ğŸ”¥ í•µì‹¬: ìœ„ ì˜ˆì‹œë¥¼ ê·¸ëŒ€ë¡œ ì“°ì§€ ë§ê³ , ì´ ë¶„ìœ„ê¸°ë¡œ ë§¤ë²ˆ ìƒˆë¡­ê²Œ ì°½ì‘í•˜ë¼!

4. ê¸¸ì´
   - {min_length}~{max_length}ì ì‚¬ì´ë¡œ ì‘ì„± (ì´ ë²”ìœ„ë¥¼ ë°˜ë“œì‹œ ì§€í‚¬ ê²ƒ)
   - ğŸš¨ ì´ëª¨ì§€ ì‚¬ìš© ê¸ˆì§€ (ì‹œìŠ¤í…œ í˜¸í™˜ì„± ë¬¸ì œ)
   - "ã…‹ã…‹", ":)", "^^" ê°™ì€ í…ìŠ¤íŠ¸ ì´ëª¨í‹°ì½˜ì€ ì„¤ì •ì— ë”°ë¼ ì‚¬ìš©
   - "ã…ã…"ëŠ” ê³ ê° ë¦¬ë·°ì— ìˆì„ ë•Œë§Œ 1íšŒ ì •ë„ ê°€ëŠ¥

5. ê¸ˆì§€
   - ë¬´ì¡°ê±´ì ì¸ ì‚¬ê³¼/ë³´ìƒ ì–¸ê¸‰(ë¦¬ë·°ì— ì´ìŠˆê°€ ìˆì„ ë•Œë§Œ)
   - ë§¤ì¥ ì •ì±…/ë‚´ë¶€ ì‚¬ì • ë³€ëª…
   - ë¦¬ë·°ì— ì—†ëŠ” ì‚¬ì‹¤ ì¶”ì •(ë©”ë‰´/ë‚ ì§œ/ë™í–‰ì¸ ë“±)
   - ë™ì¼í•œ ë§ˆë¬´ë¦¬ ë¬¸êµ¬ ë°˜ë³µ ("ë˜ ë°©ë¬¸í•´ì£¼ì„¸ìš”"ë§Œ ê³„ì† X)

[SENTIMENT HANDLING]
â­4~5 ë˜ëŠ” ê¸ì •: ë°ê³  ê°ì‚¬ ì¤‘ì‹¬ + êµ¬ì²´ í¬ì¸íŠ¸ ì–¸ê¸‰ + ì¬ë°©ë¬¸ í™˜ì˜
â­3 ë˜ëŠ” ì• ë§¤/í˜¼í•©: ê°ì‚¬ + ê³µê° + ê°œì„  ì˜ì§€(ê°€ë³ê²Œ) + ë‹¤ìŒì—” ë” ì˜í•˜ê² ë‹¤ëŠ” ì•½ì†
â­1~2 ë˜ëŠ” ë¶€ì •: ì •ì¤‘í•˜ê²Œ ì‚¬ê³¼ + í•µì‹¬ ë¶ˆí¸ ìš”ì•½ + ê°œì„  ì•½ì† + "ê°€ëŠ¥í•˜ì‹œë©´ ìì„¸í•œ ìƒí™©ì„ ë‚¨ê²¨ì£¼ì‹œë©´ í™•ì¸í•˜ê² ë‹¤(ì±„ë„ ì–¸ê¸‰ì€ ì¼ë°˜ì ìœ¼ë¡œ)"

ë‹¨, ê°œì¸ì •ë³´ ìš”êµ¬ ê¸ˆì§€. ì „í™”ë²ˆí˜¸/ì£¼ë¬¸ë²ˆí˜¸ ìš”êµ¬ X

[ë‹¤ì–‘ì„± ê°•í™” ì˜ˆì‹œ]
ê°™ì€ ê¸ì • ë¦¬ë·° 3ê°œì—ë„ ì™„ì „íˆ ë‹¤ë¥¸ ë‹µê¸€:

ë¦¬ë·°A: "ë§›ìˆì–´ìš”!"
â†’ "ì™€ì£¼ì…”ì„œ ì •ë§ ë°˜ê°€ì› ì–´ìš”^^ ë§›ì— ëŒ€í•œ ì¹­ì°¬ì´ ê°€ì¥ í° ë³´ëŒì…ë‹ˆë‹¤. ë‹¤ìŒì—ë„ ë§›ìˆê²Œ ë“œì‹¤ ìˆ˜ ìˆê²Œ ì¤€ë¹„í• ê²Œìš”!"

ë¦¬ë·°B: "ë¶„ìœ„ê¸° ì¢‹ì•„ìš”"
â†’ "í›„ê¸° í•˜ë‚˜í•˜ë‚˜ê°€ ì •ë§ í° í˜ì´ ë©ë‹ˆë‹¤. í¸ì•ˆí•œ ë¶„ìœ„ê¸° ë§Œë“¤ë ¤ê³  ì‹ ê²½ ì“´ ë¶€ë¶„ì„ ì•Œì•„ë´ì£¼ì…”ì„œ ê°ì‚¬í•´ìš”. ì–¸ì œë“  í¸í•˜ê²Œ ë°©ë¬¸í•´ì£¼ì„¸ìš”."

ë¦¬ë·°C: "ì§ì› ì¹œì ˆí•´ìš”"
â†’ "ì„¸ì‹¬í•˜ê²Œ ë´ì£¼ì…”ì„œ ê°ì‚¬í•´ìš”. ë§ì”€í•´ì£¼ì‹  ì§ì› ì¹œì ˆí•¨ì´ ì €í¬ì—ê²Œ ê°€ì¥ ì¤‘ìš”í•œ ê°€ì¹˜ì˜ˆìš”. ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”!"

ğŸ”¥ ì£¼ëª©: ì‹œì‘ë„, ë§ˆë¬´ë¦¬ë„, êµ¬ì¡°ë„ ëª¨ë‘ ë‹¤ë¦„!

**ì¶œë ¥ í˜•ì‹**
- ìµœì¢… ë‹µê¸€ë§Œ ì¶œë ¥ (ì„¤ëª… ê¸ˆì§€)
- ìì—°ìŠ¤ëŸ¬ìš´ ì¡´ëŒ“ë§ ìœ ì§€
- ğŸ”¥ ë§¤ë²ˆ ì™„ì „íˆ ìƒˆë¡œìš´ ë¬¸ì¥ êµ¬ì¡° ì‚¬ìš©

ğŸ² ëœë¤ì„± ì²´í¬ë¦¬ìŠ¤íŠ¸:
â–¡ ì´ì „ê³¼ ë‹¤ë¥¸ ì‹œì‘ ë¬¸êµ¬ ì‚¬ìš©í–ˆëŠ”ê°€?
â–¡ ì´ì „ê³¼ ë‹¤ë¥¸ ë§ˆë¬´ë¦¬ ë¬¸êµ¬ ì‚¬ìš©í–ˆëŠ”ê°€?
â–¡ ë¬¸ì¥ êµ¬ì¡°ë¥¼ ë°”ê¿¨ëŠ”ê°€? (ì˜ˆ: ê°ì‚¬â†’êµ¬ì²´â†’ë§ˆë¬´ë¦¬ vs êµ¬ì²´â†’ê³µê°â†’ê°ì‚¬)
â–¡ ìƒˆë¡œìš´ í‘œí˜„ì„ ì‹œë„í–ˆëŠ”ê°€?

ğŸš¨ ì ˆëŒ€ ê¸ˆì§€: "ê°ì‚¬í•©ë‹ˆë‹¤", "ë‹¤ìŒì— ë˜ ëµ™ê² ìŠµë‹ˆë‹¤" ê°™ì€ ë»”í•œ í‘œí˜„ ì—°ì† ì‚¬ìš©"""
            
            if request.custom_instructions:
                user_prompt += f"\n\n**ì¶”ê°€ ìš”ì²­ì‚¬í•­**\n{request.custom_instructions}"
            
            # Call OpenAI API with customized parameters
            response = client.chat.completions.create(
                model=settings.openai_model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=temperature,  # Customizable diversity
                max_tokens=max_tokens,  # Customizable length
                frequency_penalty=0.8,  # ğŸ”¥ ë°˜ë³µ íŒ¨í„´ ê°•ë ¥ ì–µì œ
                presence_penalty=0.6   # ğŸ”¥ ìƒˆë¡œìš´ í‘œí˜„ ì¥ë ¤
            )
            
            generated_reply = response.choices[0].message.content.strip()
            
            return GenerateReplyResponse(
                generated_reply=generated_reply,
                rating=request.rating,
                prompt_used=template
            )
            
        except Exception as e:
            raise HTTPException(
                status_code=500,
                detail=f"Error generating reply: {str(e)}"
            )
    
    def reload_prompts(self):
        """Reload prompt templates from file"""
        self.prompts = self._load_prompts()


# Create singleton instance
llm_service = LLMService()



